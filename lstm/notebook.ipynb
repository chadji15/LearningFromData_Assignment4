{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import datetime\n",
        "import json\n",
        "import csv\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout, Bidirectional, AveragePooling1D, AveragePooling2D, concatenate, Input\n",
        "from keras.initializers import Constant\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.layers import TextVectorization\n",
        "from keras import Model\n",
        "from keras.src.optimizers.legacy.adadelta import Adadelta\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import ParameterGrid, StratifiedKFold\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, f1_score\n",
        "\n",
        "import gc\n",
        "from tensorflow.keras import backend as k\n",
        "from tensorflow.keras.callbacks import Callback"
      ],
      "metadata": {
        "id": "Qg8C4fpkFZNZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGqpu29iFaXK",
        "outputId": "e96deff4-20df-4568-8fd5-17becf8af87f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up: Tokenizing and embedding"
      ],
      "metadata": {
        "id": "pGIec8HXgPJo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4StNkOy9Eosi"
      },
      "outputs": [],
      "source": [
        "def read_corpus(corpus_file):\n",
        "    \"\"\"Read in review data set and returns docs and labels\"\"\"\n",
        "    documents = []\n",
        "    labels = []\n",
        "    with open(corpus_file, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            tokens = line.strip()\n",
        "            documents.append(\" \".join(tokens.split()[:-1]).strip())\n",
        "            labels.append(tokens.split()[-1])\n",
        "    return documents, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_emb_matrix(voc, emb):\n",
        "    \"\"\"Get embedding matrix given vocab and the embeddings\"\"\"\n",
        "    num_tokens = len(voc) + 2\n",
        "    word_index = dict(zip(voc, range(len(voc))))\n",
        "    # Bit hacky, get embedding dimension from the word \"the\"\n",
        "    embedding_dim = len(emb[\"the\"])\n",
        "    # Prepare embedding matrix to the correct size\n",
        "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = emb.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    # Final matrix with pretrained embeddings that we can feed to embedding layer\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "9XBmp6e4FW9c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "  return word_to_vec_map"
      ],
      "metadata": {
        "id": "E2gP0xJobfTX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = read_corpus('/content/gdrive/MyDrive/University/learning_from_data/assignment_4/train.tsv')\n",
        "X_val, y_val = read_corpus('/content/gdrive/MyDrive/University/learning_from_data/assignment_4/dev.tsv')\n",
        "X_test, y_test = read_corpus('/content/gdrive/MyDrive/University/learning_from_data/assignment_4/test.tsv')"
      ],
      "metadata": {
        "id": "H6Ju1cK4Fj_U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the sake of speed only load 50 dimensional vectors here\n",
        "embeddings = read_glove_vector('/content/gdrive/MyDrive/University/learning_from_data/assignment_4/embeddings/glove.twitter.27B.200d.txt')"
      ],
      "metadata": {
        "id": "L7IBCgJBYQl1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform words to indices using a vectorizer\n",
        "vectorizer = TextVectorization(standardize=None, output_sequence_length=50)\n",
        "# Use train and dev to create vocab - could also do just train\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(X_train + X_val)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "I1nmHLUoFnWw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary mapping words to idx\n",
        "voc = vectorizer.get_vocabulary()\n",
        "emb_matrix = get_emb_matrix(voc, embeddings)"
      ],
      "metadata": {
        "id": "AqHTwbxIX9Xx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform string labels to one-hot encodings\n",
        "encoder = LabelBinarizer()\n",
        "y_train_bin = encoder.fit_transform(y_train)  # Use encoder.classes_ to find mapping back\n",
        "y_val_bin = encoder.fit_transform(y_val)\n",
        "y_test_bin = encoder.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "H4f9y952cS1Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform input to vectorized input\n",
        "X_train_vect = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
        "X_val_vect = vectorizer(np.array([[s] for s in X_val])).numpy()\n",
        "X_test_vect = vectorizer(np.array([[s] for s in X_test])).numpy()"
      ],
      "metadata": {
        "id": "wS33dNg2cUN-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = len(emb_matrix[0])\n",
        "num_tokens = len(emb_matrix)\n",
        "num_labels = len(set(y_train))"
      ],
      "metadata": {
        "id": "yAego4pQ8Cgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, Y_test, ident):\n",
        "    '''Do predictions and measure accuracy on our own test set (that we split off train)'''\n",
        "    # Get predictions using the trained model\n",
        "    Y_pred = model.predict(X_test)\n",
        "    # Finally, convert to numerical labels to get scores with sklearn\n",
        "    Y_pred = np.argmax(Y_pred, axis=1)\n",
        "    # If you have gold data, you can calculate accuracy\n",
        "    Y_test = np.argmax(Y_test, axis=1)\n",
        "    print('Accuracy on own {1} set: {0}'.format(round(accuracy_score(Y_test, Y_pred), 3), ident))\n",
        "    return accuracy_score(Y_test, Y_pred)"
      ],
      "metadata": {
        "id": "fwVZxh3kcXG5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_adaptive(y_train, emb_matrix, learning_rate, loss_function, optimizer, layers, activation):\n",
        "  \"\"\"\n",
        "  This method is a more generic version of the supplied create_model\n",
        "  function.\n",
        "\n",
        "  layers: This should contain a number of keras layers which are added to the\n",
        "  model in sequence. This way, this function can generate models with different\n",
        "  architectures.\n",
        "  \"\"\"\n",
        "\n",
        "  # Take embedding dim and size from emb_matrix\n",
        "  embedding_dim = len(emb_matrix[0])\n",
        "  num_tokens = len(emb_matrix)\n",
        "  num_labels = len(set(y_train))\n",
        "\n",
        "  # We pass the class to the grid search and then instantiate here so that the\n",
        "  # optimizer variables are freshly initialized each time\n",
        "  optimizer_initialized = optimizer()\n",
        "\n",
        "  # Set the learning rate here to make the grid search more elegant\n",
        "  optimizer_initialized.learning_rate.assign(learning_rate)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "\n",
        "  for layer in layers:\n",
        "    model.add(layer)\n",
        "\n",
        "  model.add(Dense(input_dim=embedding_dim, units=1, activation=activation, name='output'))\n",
        "  model.compile(loss=loss_function, optimizer=optimizer_initialized, metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "o-Lvn5ZocoOU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClearMemory(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()"
      ],
      "metadata": {
        "id": "KF87I79s1-VM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_adaptive(model, X_train, y_train, X_val, y_val, epochs, batch_size):\n",
        "  \"\"\"\n",
        "  This method is a more generic version of the supplied train_model function.\n",
        "  \"\"\"\n",
        "  verbose = 1\n",
        "  # Early stopping: stop training when there are three consecutive epochs without improving\n",
        "  # It's also possible to monitor the training loss with monitor=\"loss\"\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "  clear_memory_callback = ClearMemory()\n",
        "  model.fit(X_train, y_train, verbose=verbose, epochs=epochs, callbacks=[callback, clear_memory_callback], batch_size=batch_size, validation_data=(X_val, y_val))\n",
        "  return model"
      ],
      "metadata": {
        "id": "3plHAdJTcsX5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data exploration: t-SNE"
      ],
      "metadata": {
        "id": "qbbixf5Mc1wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_2d_tsne(X, y):\n",
        "  tsne = TSNE(n_components=2, init='random', perplexity=30, n_iter=250, random_state=0)\n",
        "  X_tsne = tsne.fit_transform(X)\n",
        "  X_tsne_df = pd.DataFrame.from_records(X_tsne, columns=['X_1', 'X_2'])\n",
        "  X_tsne_df['y'] = y_train\n",
        "  standard_scaler = StandardScaler()\n",
        "  X_tsne_df['X_1'], X_tsne_df['X_2'] = standard_scaler.fit_transform(np.array([X_tsne_df['X_1'], X_tsne_df['X_2']]).T).T\n",
        "  return X_tsne_df"
      ],
      "metadata": {
        "id": "_ga7l7MccwwW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_lstm_layers = [\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(64),\n",
        "]\n",
        "\n",
        "initial_lstm_model = create_model_adaptive(\n",
        "  y_train=y_train,\n",
        "  emb_matrix=emb_matrix,\n",
        "  learning_rate=0.001,\n",
        "  loss_function='mse',\n",
        "  activation='sigmoid',\n",
        "  optimizer=Adam,\n",
        "  layers=initial_lstm_layers,\n",
        ")\n",
        "\n",
        "initial_lstm_model = train_model_adaptive(\n",
        "  model=initial_lstm_model,\n",
        "  X_train=X_train_vect,\n",
        "  y_train=y_train_bin,\n",
        "  X_val=X_val_vect,\n",
        "  y_val=y_val_bin,\n",
        "  epochs=50,\n",
        "  batch_size=256,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o62VLKVlc1OR",
        "outputId": "404b2847-62a6-4628-a1d8-0a0f8b2d4376"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "48/48 [==============================] - 8s 43ms/step - loss: 0.2236 - accuracy: 0.6666 - val_loss: 0.2051 - val_accuracy: 0.6930\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.1893 - accuracy: 0.7240 - val_loss: 0.1816 - val_accuracy: 0.7460\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 3s 35ms/step - loss: 0.1754 - accuracy: 0.7519 - val_loss: 0.1834 - val_accuracy: 0.7370\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 2s 27ms/step - loss: 0.1704 - accuracy: 0.7569 - val_loss: 0.1746 - val_accuracy: 0.7410\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 2s 29ms/step - loss: 0.1657 - accuracy: 0.7670 - val_loss: 0.1823 - val_accuracy: 0.7400\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 2s 28ms/step - loss: 0.1641 - accuracy: 0.7715 - val_loss: 0.1764 - val_accuracy: 0.7380\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 2s 26ms/step - loss: 0.1591 - accuracy: 0.7797 - val_loss: 0.1785 - val_accuracy: 0.7390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = Model(inputs=initial_lstm_model.inputs,\n",
        "                        outputs=[layer.output for layer in initial_lstm_model.layers])\n",
        "features = extractor(X_train_vect)"
      ],
      "metadata": {
        "id": "jL2kdI8xc5iA"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = features[0]\n",
        "lstm_output_1 = np.take(features[1], -1, axis=1) # Take last element her since sequences are returned\n",
        "lstm_output_2 = np.take(features[2], -1, axis=1) # Take last element her since sequences are returned\n",
        "lstm_output_3 = features[3]\n",
        "\n",
        "intermediate_outputs = [\n",
        "    (np.max(input, axis=1), 'Embeddings (max)'),\n",
        "    (lstm_output_1, 'LSTM output (layer 1)'),\n",
        "    (lstm_output_2, 'LSTM output (layer 2)'),\n",
        "    (lstm_output_3, 'LSTM output (layer 3)'),\n",
        "]\n",
        "\n",
        "plot_df = pd.DataFrame({})\n",
        "\n",
        "for X, name in intermediate_outputs:\n",
        "  X_tsne_df = plot_2d_tsne(X, y_train)\n",
        "  X_tsne_df['name'] = name\n",
        "  plot_df = pd.concat([plot_df, X_tsne_df])"
      ],
      "metadata": {
        "id": "ESzolaSSc9M5"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.relplot(data=plot_df, x='X_1', y='X_2', hue='y', col='name', alpha=0.7, col_wrap=2)\n",
        "\n",
        "plt.savefig(f'/content/gdrive/MyDrive/University/learning_from_data/assignment_4/plots/manifold_{datetime.datetime.now().isoformat()}.svg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AK1L2IL1dArb",
        "outputId": "340d2a89-84d7-48b4-d416-15603ad1d63c"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1079.75x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data exploration: Imbalance with initial model predictions"
      ],
      "metadata": {
        "id": "eeDTDyLehV0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_test_bin, y_pred):\n",
        "  cm = confusion_matrix(\n",
        "  encoder.inverse_transform(y_test_bin),\n",
        "  encoder.inverse_transform(y_pred),\n",
        "  labels=encoder.classes_\n",
        "  )\n",
        "  sns.set_style('white')\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=encoder.classes_)\n",
        "  disp.plot()\n",
        "  plt.savefig('confusion.png')"
      ],
      "metadata": {
        "id": "rN7cc4XHzWo0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = [[1] if n > 0.5 else [0] for [n] in initial_lstm_model.predict(X_test_vect)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwjEBaD-6raj",
        "outputId": "e36e12d2-2ddb-4c5c-ed7a-82c0767a1c69"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test_bin, initial_lstm_model.predict(X_test_vect))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Nw7NI8522yZM",
        "outputId": "2efd3b1b-b902-4a2b-a7f1-b74374c94e10"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test_bin, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcrOOwWB7SKz",
        "outputId": "6d5290db-88ca-48d3-974f-f6b8266f4ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.96      0.87       620\n",
            "           1       0.79      0.38      0.51       240\n",
            "\n",
            "    accuracy                           0.80       860\n",
            "   macro avg       0.79      0.67      0.69       860\n",
            "weighted avg       0.80      0.80      0.77       860\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up: Grid search functions"
      ],
      "metadata": {
        "id": "iO5WIZ-9hEwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_grid_search(grid_search_params, emb_matrix, X_train_vect, y_train_bin, X_val_vect, y_val_bin, y_train, results_path, n_iterations, X_test_vect, y_test_bin):\n",
        "  results = []\n",
        "\n",
        "  for params in grid_search_params:\n",
        "    for n_iteration in range(0, n_iterations):\n",
        "      # This is a bit cryptic maybe, but it allows me to easily re-use this grid\n",
        "      # search function with multiple architectures\n",
        "      layers = params['set_up_function'](params)\n",
        "\n",
        "      # Create model\n",
        "      model = create_model_adaptive(\n",
        "        y_train=y_train,\n",
        "        emb_matrix=emb_matrix,\n",
        "        learning_rate=params['learning_rate'],\n",
        "        loss_function=params['loss_function'],\n",
        "        optimizer=params['optimizer'],\n",
        "        activation=params['activation'],\n",
        "        layers=layers\n",
        "      )\n",
        "      # Train the model\n",
        "      model = train_model_adaptive(\n",
        "        model=model,\n",
        "        X_train=X_train_vect,\n",
        "        y_train=y_train_bin,\n",
        "        X_val=X_val_vect,\n",
        "        y_val=y_val_bin,\n",
        "        epochs=params['epochs'],\n",
        "        batch_size=params['batch_size'],\n",
        "      )\n",
        "      results_with_params = params.copy()\n",
        "      y_pred_val = [[1] if n > 0.5 else [0] for [n] in model.predict(X_val_vect)]\n",
        "      y_pred_test = [[1] if n > 0.5 else [0] for [n] in model.predict(X_test_vect)]\n",
        "      results_with_params['f1_score_validation'] = f1_score(y_val_bin, y_pred_val, average='macro')\n",
        "      results_with_params['f1_score_test'] = f1_score(y_test_bin, y_pred_test, average='macro')\n",
        "      results_with_params['run_number'] = n_iteration\n",
        "      results.append(results_with_params)\n",
        "\n",
        "  results_df = pd.DataFrame.from_records(results)\n",
        "  results_df.to_csv(results_path)"
      ],
      "metadata": {
        "id": "IEfygGIs0Rdy"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_grid_search_params_alternate_architectures():\n",
        "  param_grid = {\n",
        "    'learning_rate': [0.0005, 0.001, 0.003],\n",
        "    'activation': ['sigmoid', 'relu'],\n",
        "    'loss_function': ['mse', 'poisson'],\n",
        "    'optimizer': [Adam],\n",
        "    'batch_size': [64, 128, 256],\n",
        "    'epochs': [50],\n",
        "    'set_up_function': [\n",
        "        set_up_candidate_one,\n",
        "    ]\n",
        "  }\n",
        "  return ParameterGrid(param_grid)"
      ],
      "metadata": {
        "id": "-L2NfOxIxot3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_up_candidate_one(params):\n",
        "  layers = []\n",
        "  layers.append(Bidirectional(LSTM(64)))\n",
        "  layers.append(Dense(64))\n",
        "  return layers"
      ],
      "metadata": {
        "id": "hDwifmhPxewc"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid search: Run and evaluation"
      ],
      "metadata": {
        "id": "i1OTxVjKhnoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_one_path = f'/content/gdrive/MyDrive/University/learning_from_data/assignment_4/results/grid_search_one_results.csv'"
      ],
      "metadata": {
        "id": "YFyFgt-BL0P1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_grid_search(\n",
        "    generate_grid_search_params_alternate_architectures(),\n",
        "    emb_matrix,\n",
        "    X_train_vect,\n",
        "    y_train_bin,\n",
        "    X_val_vect,\n",
        "    y_val_bin,\n",
        "    y_train,\n",
        "    grid_search_one_path,\n",
        "    3,\n",
        "    X_test_vect,\n",
        "    y_test_bin\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyaTlbWy-Qsc",
        "outputId": "04005ad0-0dbf-44ce-e9ca-6cd1a40886e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/192 [==============================] - 12s 13ms/step - loss: 0.2070 - accuracy: 0.6910 - val_loss: 0.1828 - val_accuracy: 0.7390\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1788 - accuracy: 0.7441 - val_loss: 0.1779 - val_accuracy: 0.7430\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.1699 - accuracy: 0.7572 - val_loss: 0.1798 - val_accuracy: 0.7370\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.1646 - accuracy: 0.7658 - val_loss: 0.1728 - val_accuracy: 0.7490\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1604 - accuracy: 0.7771 - val_loss: 0.1769 - val_accuracy: 0.7380\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1550 - accuracy: 0.7848 - val_loss: 0.1800 - val_accuracy: 0.7350\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1485 - accuracy: 0.7969 - val_loss: 0.1768 - val_accuracy: 0.7500\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 21ms/step - loss: 0.2025 - accuracy: 0.6995 - val_loss: 0.1788 - val_accuracy: 0.7360\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1769 - accuracy: 0.7452 - val_loss: 0.1737 - val_accuracy: 0.7520\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.1689 - accuracy: 0.7590 - val_loss: 0.1709 - val_accuracy: 0.7600\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1647 - accuracy: 0.7681 - val_loss: 0.1692 - val_accuracy: 0.7600\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1610 - accuracy: 0.7747 - val_loss: 0.1707 - val_accuracy: 0.7580\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1556 - accuracy: 0.7848 - val_loss: 0.1714 - val_accuracy: 0.7580\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 13ms/step - loss: 0.1493 - accuracy: 0.7969 - val_loss: 0.1740 - val_accuracy: 0.7520\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 6s 12ms/step - loss: 0.2019 - accuracy: 0.7034 - val_loss: 0.1885 - val_accuracy: 0.7270\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1768 - accuracy: 0.7484 - val_loss: 0.1775 - val_accuracy: 0.7470\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1702 - accuracy: 0.7614 - val_loss: 0.1763 - val_accuracy: 0.7490\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.1640 - accuracy: 0.7676 - val_loss: 0.1763 - val_accuracy: 0.7510\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.1601 - accuracy: 0.7776 - val_loss: 0.1734 - val_accuracy: 0.7550\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1546 - accuracy: 0.7859 - val_loss: 0.1744 - val_accuracy: 0.7620\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1471 - accuracy: 0.7980 - val_loss: 0.1798 - val_accuracy: 0.7380\n",
            "Epoch 8/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1395 - accuracy: 0.8103 - val_loss: 0.1811 - val_accuracy: 0.7490\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 16ms/step - loss: 0.6703 - accuracy: 0.6952 - val_loss: 0.6838 - val_accuracy: 0.6890\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6385 - accuracy: 0.7338 - val_loss: 0.6551 - val_accuracy: 0.7460\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6258 - accuracy: 0.7539 - val_loss: 0.6540 - val_accuracy: 0.7450\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6189 - accuracy: 0.7560 - val_loss: 0.6538 - val_accuracy: 0.7580\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6088 - accuracy: 0.7674 - val_loss: 0.6482 - val_accuracy: 0.7540\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.5996 - accuracy: 0.7724 - val_loss: 0.6787 - val_accuracy: 0.7550\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 13ms/step - loss: 0.5908 - accuracy: 0.7815 - val_loss: 0.6571 - val_accuracy: 0.7490\n",
            "Epoch 8/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.5766 - accuracy: 0.7979 - val_loss: 0.6715 - val_accuracy: 0.7350\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 6s 13ms/step - loss: 0.6774 - accuracy: 0.6871 - val_loss: 0.6729 - val_accuracy: 0.7180\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6377 - accuracy: 0.7383 - val_loss: 0.6560 - val_accuracy: 0.7390\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 13ms/step - loss: 0.6277 - accuracy: 0.7509 - val_loss: 0.6593 - val_accuracy: 0.7520\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.6182 - accuracy: 0.7586 - val_loss: 0.6527 - val_accuracy: 0.7540\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6068 - accuracy: 0.7694 - val_loss: 0.6539 - val_accuracy: 0.7300\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.5965 - accuracy: 0.7791 - val_loss: 0.6578 - val_accuracy: 0.7480\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.5835 - accuracy: 0.7861 - val_loss: 0.6611 - val_accuracy: 0.7270\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 15ms/step - loss: 0.6700 - accuracy: 0.7005 - val_loss: 0.6610 - val_accuracy: 0.7400\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6341 - accuracy: 0.7438 - val_loss: 0.6518 - val_accuracy: 0.7460\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6248 - accuracy: 0.7538 - val_loss: 0.6632 - val_accuracy: 0.7030\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6154 - accuracy: 0.7634 - val_loss: 0.6552 - val_accuracy: 0.7200\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6065 - accuracy: 0.7683 - val_loss: 0.6527 - val_accuracy: 0.7480\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 15ms/step - loss: 0.1987 - accuracy: 0.7076 - val_loss: 0.1847 - val_accuracy: 0.7360\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1736 - accuracy: 0.7494 - val_loss: 0.1764 - val_accuracy: 0.7580\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1659 - accuracy: 0.7625 - val_loss: 0.1829 - val_accuracy: 0.7320\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1587 - accuracy: 0.7750 - val_loss: 0.1726 - val_accuracy: 0.7560\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1504 - accuracy: 0.7905 - val_loss: 0.1726 - val_accuracy: 0.7440\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.1408 - accuracy: 0.8070 - val_loss: 0.1858 - val_accuracy: 0.7490\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.1307 - accuracy: 0.8248 - val_loss: 0.1916 - val_accuracy: 0.7370\n",
            "Epoch 8/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.1173 - accuracy: 0.8437 - val_loss: 0.1984 - val_accuracy: 0.7150\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 18ms/step - loss: 0.1949 - accuracy: 0.7150 - val_loss: 0.1812 - val_accuracy: 0.7520\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.1735 - accuracy: 0.7525 - val_loss: 0.1740 - val_accuracy: 0.7590\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1654 - accuracy: 0.7640 - val_loss: 0.1704 - val_accuracy: 0.7670\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1589 - accuracy: 0.7755 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1512 - accuracy: 0.7904 - val_loss: 0.1757 - val_accuracy: 0.7490\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1410 - accuracy: 0.8092 - val_loss: 0.1800 - val_accuracy: 0.7500\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 16ms/step - loss: 0.1968 - accuracy: 0.7122 - val_loss: 0.1803 - val_accuracy: 0.7340\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1746 - accuracy: 0.7508 - val_loss: 0.1738 - val_accuracy: 0.7540\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1663 - accuracy: 0.7639 - val_loss: 0.1751 - val_accuracy: 0.7430\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1598 - accuracy: 0.7783 - val_loss: 0.1729 - val_accuracy: 0.7670\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.1519 - accuracy: 0.7892 - val_loss: 0.1747 - val_accuracy: 0.7520\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 0.1428 - accuracy: 0.8061 - val_loss: 0.1783 - val_accuracy: 0.7450\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1306 - accuracy: 0.8227 - val_loss: 0.1847 - val_accuracy: 0.7500\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 14ms/step - loss: 0.6602 - accuracy: 0.7130 - val_loss: 0.6531 - val_accuracy: 0.7400\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6307 - accuracy: 0.7471 - val_loss: 0.6514 - val_accuracy: 0.7480\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6211 - accuracy: 0.7608 - val_loss: 0.6562 - val_accuracy: 0.7280\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6114 - accuracy: 0.7710 - val_loss: 0.6414 - val_accuracy: 0.7590\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.5994 - accuracy: 0.7791 - val_loss: 0.6686 - val_accuracy: 0.7460\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.5834 - accuracy: 0.7882 - val_loss: 0.6574 - val_accuracy: 0.7470\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.5646 - accuracy: 0.8076 - val_loss: 0.6576 - val_accuracy: 0.7350\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 19ms/step - loss: 0.6669 - accuracy: 0.7030 - val_loss: 0.6590 - val_accuracy: 0.7300\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6312 - accuracy: 0.7488 - val_loss: 0.6561 - val_accuracy: 0.7510\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6185 - accuracy: 0.7607 - val_loss: 0.6493 - val_accuracy: 0.7570\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6051 - accuracy: 0.7752 - val_loss: 0.6494 - val_accuracy: 0.7490\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.5929 - accuracy: 0.7812 - val_loss: 0.6572 - val_accuracy: 0.7380\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.5741 - accuracy: 0.8005 - val_loss: 0.6637 - val_accuracy: 0.7240\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 17ms/step - loss: 0.6691 - accuracy: 0.7025 - val_loss: 0.6633 - val_accuracy: 0.7330\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6320 - accuracy: 0.7480 - val_loss: 0.6516 - val_accuracy: 0.7490\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6207 - accuracy: 0.7605 - val_loss: 0.6534 - val_accuracy: 0.7610\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6086 - accuracy: 0.7718 - val_loss: 0.6457 - val_accuracy: 0.7610\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.5922 - accuracy: 0.7858 - val_loss: 0.6526 - val_accuracy: 0.7340\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.5751 - accuracy: 0.8007 - val_loss: 0.6605 - val_accuracy: 0.7400\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.5572 - accuracy: 0.8145 - val_loss: 0.6884 - val_accuracy: 0.7210\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 6s 14ms/step - loss: 0.1931 - accuracy: 0.7215 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.1694 - accuracy: 0.7622 - val_loss: 0.1741 - val_accuracy: 0.7490\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.1614 - accuracy: 0.7753 - val_loss: 0.1728 - val_accuracy: 0.7560\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1494 - accuracy: 0.7903 - val_loss: 0.1793 - val_accuracy: 0.7470\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1341 - accuracy: 0.8172 - val_loss: 0.1902 - val_accuracy: 0.7360\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1132 - accuracy: 0.8499 - val_loss: 0.1956 - val_accuracy: 0.7320\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 6s 13ms/step - loss: 0.1977 - accuracy: 0.7121 - val_loss: 0.1803 - val_accuracy: 0.7350\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.1715 - accuracy: 0.7569 - val_loss: 0.1730 - val_accuracy: 0.7580\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.1623 - accuracy: 0.7714 - val_loss: 0.1705 - val_accuracy: 0.7600\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1522 - accuracy: 0.7917 - val_loss: 0.1744 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1395 - accuracy: 0.8095 - val_loss: 0.1795 - val_accuracy: 0.7430\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1210 - accuracy: 0.8367 - val_loss: 0.1876 - val_accuracy: 0.7430\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 19ms/step - loss: 0.1916 - accuracy: 0.7231 - val_loss: 0.1758 - val_accuracy: 0.7570\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1699 - accuracy: 0.7605 - val_loss: 0.1686 - val_accuracy: 0.7480\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1606 - accuracy: 0.7745 - val_loss: 0.1717 - val_accuracy: 0.7550\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1485 - accuracy: 0.7933 - val_loss: 0.1744 - val_accuracy: 0.7530\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.1333 - accuracy: 0.8199 - val_loss: 0.1863 - val_accuracy: 0.7370\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 13ms/step - loss: 0.6558 - accuracy: 0.7239 - val_loss: 0.6519 - val_accuracy: 0.7440\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6241 - accuracy: 0.7564 - val_loss: 0.6465 - val_accuracy: 0.7660\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6082 - accuracy: 0.7743 - val_loss: 0.6523 - val_accuracy: 0.7480\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.5868 - accuracy: 0.7902 - val_loss: 0.6677 - val_accuracy: 0.7380\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.5581 - accuracy: 0.8166 - val_loss: 0.6765 - val_accuracy: 0.7410\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 13ms/step - loss: 0.6582 - accuracy: 0.7172 - val_loss: 0.6511 - val_accuracy: 0.7550\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6260 - accuracy: 0.7589 - val_loss: 0.6472 - val_accuracy: 0.7510\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6094 - accuracy: 0.7743 - val_loss: 0.6506 - val_accuracy: 0.7510\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.5916 - accuracy: 0.7855 - val_loss: 0.6606 - val_accuracy: 0.7520\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.5646 - accuracy: 0.8099 - val_loss: 0.6750 - val_accuracy: 0.7480\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 6s 13ms/step - loss: 0.6577 - accuracy: 0.7158 - val_loss: 0.6520 - val_accuracy: 0.7520\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6270 - accuracy: 0.7520 - val_loss: 0.6516 - val_accuracy: 0.7460\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.6105 - accuracy: 0.7669 - val_loss: 0.6489 - val_accuracy: 0.7490\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.5918 - accuracy: 0.7841 - val_loss: 0.6597 - val_accuracy: 0.7450\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.5631 - accuracy: 0.8096 - val_loss: 0.6719 - val_accuracy: 0.7260\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 9ms/step - loss: 0.5320 - accuracy: 0.8310 - val_loss: 0.7397 - val_accuracy: 0.7260\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 16ms/step - loss: 0.2111 - accuracy: 0.6863 - val_loss: 0.1883 - val_accuracy: 0.7290\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1824 - accuracy: 0.7384 - val_loss: 0.1891 - val_accuracy: 0.7210\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1744 - accuracy: 0.7509 - val_loss: 0.1766 - val_accuracy: 0.7420\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1688 - accuracy: 0.7600 - val_loss: 0.1750 - val_accuracy: 0.7360\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1640 - accuracy: 0.7696 - val_loss: 0.1732 - val_accuracy: 0.7490\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1600 - accuracy: 0.7768 - val_loss: 0.1739 - val_accuracy: 0.7560\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1576 - accuracy: 0.7789 - val_loss: 0.1726 - val_accuracy: 0.7550\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1508 - accuracy: 0.7903 - val_loss: 0.1791 - val_accuracy: 0.7360\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1449 - accuracy: 0.8034 - val_loss: 0.1805 - val_accuracy: 0.7420\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1389 - accuracy: 0.8141 - val_loss: 0.1834 - val_accuracy: 0.7310\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.2142 - accuracy: 0.6832 - val_loss: 0.1867 - val_accuracy: 0.7230\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1811 - accuracy: 0.7372 - val_loss: 0.1770 - val_accuracy: 0.7360\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1726 - accuracy: 0.7560 - val_loss: 0.1737 - val_accuracy: 0.7520\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1688 - accuracy: 0.7580 - val_loss: 0.1769 - val_accuracy: 0.7340\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1635 - accuracy: 0.7676 - val_loss: 0.1722 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1594 - accuracy: 0.7770 - val_loss: 0.1803 - val_accuracy: 0.7310\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1538 - accuracy: 0.7864 - val_loss: 0.1726 - val_accuracy: 0.7550\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1496 - accuracy: 0.7931 - val_loss: 0.1787 - val_accuracy: 0.7370\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 17ms/step - loss: 0.2099 - accuracy: 0.6879 - val_loss: 0.1917 - val_accuracy: 0.7220\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1820 - accuracy: 0.7374 - val_loss: 0.1827 - val_accuracy: 0.7330\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1739 - accuracy: 0.7516 - val_loss: 0.1812 - val_accuracy: 0.7430\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1696 - accuracy: 0.7623 - val_loss: 0.1766 - val_accuracy: 0.7430\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1649 - accuracy: 0.7663 - val_loss: 0.1791 - val_accuracy: 0.7390\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1605 - accuracy: 0.7752 - val_loss: 0.1753 - val_accuracy: 0.7520\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1564 - accuracy: 0.7823 - val_loss: 0.1845 - val_accuracy: 0.7220\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1514 - accuracy: 0.7921 - val_loss: 0.1793 - val_accuracy: 0.7380\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1443 - accuracy: 0.8041 - val_loss: 0.1810 - val_accuracy: 0.7410\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.6869 - accuracy: 0.6750 - val_loss: 0.6839 - val_accuracy: 0.7030\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.6469 - accuracy: 0.7230 - val_loss: 0.6593 - val_accuracy: 0.7330\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6306 - accuracy: 0.7454 - val_loss: 0.6618 - val_accuracy: 0.7490\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6233 - accuracy: 0.7529 - val_loss: 0.6508 - val_accuracy: 0.7590\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6168 - accuracy: 0.7587 - val_loss: 0.6500 - val_accuracy: 0.7450\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6100 - accuracy: 0.7664 - val_loss: 0.6520 - val_accuracy: 0.7360\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6026 - accuracy: 0.7724 - val_loss: 0.6501 - val_accuracy: 0.7490\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.5960 - accuracy: 0.7802 - val_loss: 0.6619 - val_accuracy: 0.7320\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 17ms/step - loss: 0.6803 - accuracy: 0.6822 - val_loss: 0.6806 - val_accuracy: 0.6990\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6413 - accuracy: 0.7325 - val_loss: 0.6624 - val_accuracy: 0.7280\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.6280 - accuracy: 0.7478 - val_loss: 0.6566 - val_accuracy: 0.7400\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6228 - accuracy: 0.7558 - val_loss: 0.6520 - val_accuracy: 0.7540\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6163 - accuracy: 0.7602 - val_loss: 0.6545 - val_accuracy: 0.7490\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6075 - accuracy: 0.7678 - val_loss: 0.6555 - val_accuracy: 0.7610\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.5994 - accuracy: 0.7717 - val_loss: 0.6575 - val_accuracy: 0.7490\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 7s 18ms/step - loss: 0.6890 - accuracy: 0.6681 - val_loss: 0.6705 - val_accuracy: 0.7120\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6403 - accuracy: 0.7349 - val_loss: 0.6576 - val_accuracy: 0.7380\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6276 - accuracy: 0.7488 - val_loss: 0.6500 - val_accuracy: 0.7410\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6216 - accuracy: 0.7556 - val_loss: 0.6464 - val_accuracy: 0.7520\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6135 - accuracy: 0.7619 - val_loss: 0.6489 - val_accuracy: 0.7570\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6094 - accuracy: 0.7690 - val_loss: 0.6452 - val_accuracy: 0.7610\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6015 - accuracy: 0.7708 - val_loss: 0.6470 - val_accuracy: 0.7520\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.5930 - accuracy: 0.7783 - val_loss: 0.6520 - val_accuracy: 0.7650\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.5838 - accuracy: 0.7871 - val_loss: 0.6609 - val_accuracy: 0.7160\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 17ms/step - loss: 0.2019 - accuracy: 0.7004 - val_loss: 0.1818 - val_accuracy: 0.7370\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.7510 - val_loss: 0.1766 - val_accuracy: 0.7430\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.1682 - accuracy: 0.7592 - val_loss: 0.1731 - val_accuracy: 0.7460\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1633 - accuracy: 0.7703 - val_loss: 0.1755 - val_accuracy: 0.7400\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1563 - accuracy: 0.7823 - val_loss: 0.1829 - val_accuracy: 0.7330\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1499 - accuracy: 0.7926 - val_loss: 0.1739 - val_accuracy: 0.7530\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 17ms/step - loss: 0.2052 - accuracy: 0.6943 - val_loss: 0.1858 - val_accuracy: 0.7460\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1771 - accuracy: 0.7488 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.1677 - accuracy: 0.7619 - val_loss: 0.1755 - val_accuracy: 0.7430\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1617 - accuracy: 0.7714 - val_loss: 0.1827 - val_accuracy: 0.7360\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1534 - accuracy: 0.7864 - val_loss: 0.1784 - val_accuracy: 0.7320\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1454 - accuracy: 0.8025 - val_loss: 0.1809 - val_accuracy: 0.7520\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.2047 - accuracy: 0.6970 - val_loss: 0.1882 - val_accuracy: 0.7310\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1773 - accuracy: 0.7436 - val_loss: 0.1792 - val_accuracy: 0.7350\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1680 - accuracy: 0.7623 - val_loss: 0.1757 - val_accuracy: 0.7540\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1628 - accuracy: 0.7721 - val_loss: 0.1731 - val_accuracy: 0.7510\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1561 - accuracy: 0.7829 - val_loss: 0.1705 - val_accuracy: 0.7570\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1475 - accuracy: 0.7978 - val_loss: 0.1793 - val_accuracy: 0.7390\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1404 - accuracy: 0.8109 - val_loss: 0.1813 - val_accuracy: 0.7570\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1295 - accuracy: 0.8270 - val_loss: 0.1923 - val_accuracy: 0.7370\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.6701 - accuracy: 0.6958 - val_loss: 0.6726 - val_accuracy: 0.7310\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6331 - accuracy: 0.7435 - val_loss: 0.6507 - val_accuracy: 0.7560\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.6224 - accuracy: 0.7567 - val_loss: 0.6504 - val_accuracy: 0.7440\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6107 - accuracy: 0.7687 - val_loss: 0.6499 - val_accuracy: 0.7580\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6038 - accuracy: 0.7727 - val_loss: 0.6464 - val_accuracy: 0.7490\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.5903 - accuracy: 0.7843 - val_loss: 0.6530 - val_accuracy: 0.7530\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.5774 - accuracy: 0.7928 - val_loss: 0.6586 - val_accuracy: 0.7250\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.5592 - accuracy: 0.8095 - val_loss: 0.6897 - val_accuracy: 0.6770\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 7s 17ms/step - loss: 0.6762 - accuracy: 0.6843 - val_loss: 0.6677 - val_accuracy: 0.7200\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.6361 - accuracy: 0.7393 - val_loss: 0.6600 - val_accuracy: 0.7450\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6247 - accuracy: 0.7533 - val_loss: 0.6503 - val_accuracy: 0.7460\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6141 - accuracy: 0.7639 - val_loss: 0.6485 - val_accuracy: 0.7550\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6051 - accuracy: 0.7699 - val_loss: 0.6546 - val_accuracy: 0.7550\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.5915 - accuracy: 0.7821 - val_loss: 0.6534 - val_accuracy: 0.7560\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.5769 - accuracy: 0.7934 - val_loss: 0.6660 - val_accuracy: 0.7390\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.6748 - accuracy: 0.6900 - val_loss: 0.6637 - val_accuracy: 0.7300\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6333 - accuracy: 0.7463 - val_loss: 0.6565 - val_accuracy: 0.7220\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6223 - accuracy: 0.7560 - val_loss: 0.6506 - val_accuracy: 0.7520\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6135 - accuracy: 0.7665 - val_loss: 0.6453 - val_accuracy: 0.7530\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6056 - accuracy: 0.7719 - val_loss: 0.6539 - val_accuracy: 0.7460\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.5915 - accuracy: 0.7841 - val_loss: 0.6602 - val_accuracy: 0.7520\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.5754 - accuracy: 0.7993 - val_loss: 0.6603 - val_accuracy: 0.7530\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.1961 - accuracy: 0.7123 - val_loss: 0.1797 - val_accuracy: 0.7420\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1706 - accuracy: 0.7596 - val_loss: 0.1719 - val_accuracy: 0.7510\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1619 - accuracy: 0.7735 - val_loss: 0.1720 - val_accuracy: 0.7480\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1515 - accuracy: 0.7908 - val_loss: 0.1726 - val_accuracy: 0.7490\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1400 - accuracy: 0.8094 - val_loss: 0.1825 - val_accuracy: 0.7440\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 19ms/step - loss: 0.1996 - accuracy: 0.7074 - val_loss: 0.1787 - val_accuracy: 0.7470\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1724 - accuracy: 0.7560 - val_loss: 0.1710 - val_accuracy: 0.7590\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1629 - accuracy: 0.7733 - val_loss: 0.1710 - val_accuracy: 0.7650\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1528 - accuracy: 0.7906 - val_loss: 0.1744 - val_accuracy: 0.7480\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1391 - accuracy: 0.8113 - val_loss: 0.1854 - val_accuracy: 0.7310\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1256 - accuracy: 0.8318 - val_loss: 0.1994 - val_accuracy: 0.7180\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 6s 22ms/step - loss: 0.1929 - accuracy: 0.7196 - val_loss: 0.1814 - val_accuracy: 0.7390\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1698 - accuracy: 0.7596 - val_loss: 0.1740 - val_accuracy: 0.7540\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1618 - accuracy: 0.7734 - val_loss: 0.1723 - val_accuracy: 0.7490\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1511 - accuracy: 0.7915 - val_loss: 0.1774 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1381 - accuracy: 0.8129 - val_loss: 0.1838 - val_accuracy: 0.7460\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1231 - accuracy: 0.8365 - val_loss: 0.1937 - val_accuracy: 0.7250\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.6612 - accuracy: 0.7132 - val_loss: 0.6643 - val_accuracy: 0.7370\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6279 - accuracy: 0.7545 - val_loss: 0.6471 - val_accuracy: 0.7490\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6131 - accuracy: 0.7692 - val_loss: 0.6464 - val_accuracy: 0.7550\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.5954 - accuracy: 0.7838 - val_loss: 0.6684 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.5741 - accuracy: 0.7988 - val_loss: 0.6720 - val_accuracy: 0.7490\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.5419 - accuracy: 0.8243 - val_loss: 0.7399 - val_accuracy: 0.7440\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 6s 25ms/step - loss: 0.6626 - accuracy: 0.7089 - val_loss: 0.6577 - val_accuracy: 0.7420\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6301 - accuracy: 0.7475 - val_loss: 0.6472 - val_accuracy: 0.7570\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6104 - accuracy: 0.7699 - val_loss: 0.6448 - val_accuracy: 0.7530\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.5941 - accuracy: 0.7835 - val_loss: 0.6736 - val_accuracy: 0.7550\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.5693 - accuracy: 0.8035 - val_loss: 0.6675 - val_accuracy: 0.7430\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 46ms/step - loss: 0.5410 - accuracy: 0.8256 - val_loss: 0.7459 - val_accuracy: 0.7580\n",
            "32/32 [==============================] - 1s 21ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 12s 77ms/step - loss: 0.6601 - accuracy: 0.7119 - val_loss: 0.6665 - val_accuracy: 0.7320\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6278 - accuracy: 0.7552 - val_loss: 0.6510 - val_accuracy: 0.7560\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6143 - accuracy: 0.7681 - val_loss: 0.6520 - val_accuracy: 0.7490\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.5979 - accuracy: 0.7788 - val_loss: 0.6561 - val_accuracy: 0.7330\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.5761 - accuracy: 0.7990 - val_loss: 0.6713 - val_accuracy: 0.7330\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 6s 25ms/step - loss: 0.2265 - accuracy: 0.6665 - val_loss: 0.2203 - val_accuracy: 0.6500\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1950 - accuracy: 0.7029 - val_loss: 0.1853 - val_accuracy: 0.7290\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1765 - accuracy: 0.7480 - val_loss: 0.1787 - val_accuracy: 0.7450\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1717 - accuracy: 0.7534 - val_loss: 0.1752 - val_accuracy: 0.7470\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1678 - accuracy: 0.7608 - val_loss: 0.1747 - val_accuracy: 0.7460\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1643 - accuracy: 0.7692 - val_loss: 0.1728 - val_accuracy: 0.7560\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1620 - accuracy: 0.7743 - val_loss: 0.1766 - val_accuracy: 0.7410\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1594 - accuracy: 0.7800 - val_loss: 0.1744 - val_accuracy: 0.7510\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1596 - accuracy: 0.7803 - val_loss: 0.1743 - val_accuracy: 0.7450\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 25ms/step - loss: 0.2253 - accuracy: 0.6618 - val_loss: 0.2162 - val_accuracy: 0.6590\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1933 - accuracy: 0.7088 - val_loss: 0.1893 - val_accuracy: 0.7240\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1789 - accuracy: 0.7445 - val_loss: 0.1824 - val_accuracy: 0.7390\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1729 - accuracy: 0.7531 - val_loss: 0.1807 - val_accuracy: 0.7410\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1687 - accuracy: 0.7593 - val_loss: 0.1768 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1648 - accuracy: 0.7661 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1620 - accuracy: 0.7745 - val_loss: 0.1766 - val_accuracy: 0.7540\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1589 - accuracy: 0.7769 - val_loss: 0.1747 - val_accuracy: 0.7520\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1552 - accuracy: 0.7854 - val_loss: 0.1827 - val_accuracy: 0.7230\n",
            "Epoch 10/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1506 - accuracy: 0.7929 - val_loss: 0.1782 - val_accuracy: 0.7570\n",
            "Epoch 11/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1463 - accuracy: 0.7990 - val_loss: 0.1838 - val_accuracy: 0.7300\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 25ms/step - loss: 0.2246 - accuracy: 0.6677 - val_loss: 0.2122 - val_accuracy: 0.6600\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1907 - accuracy: 0.7188 - val_loss: 0.1846 - val_accuracy: 0.7280\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1768 - accuracy: 0.7458 - val_loss: 0.1820 - val_accuracy: 0.7370\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1740 - accuracy: 0.7522 - val_loss: 0.1780 - val_accuracy: 0.7420\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1675 - accuracy: 0.7615 - val_loss: 0.1773 - val_accuracy: 0.7480\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1630 - accuracy: 0.7690 - val_loss: 0.1763 - val_accuracy: 0.7450\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1595 - accuracy: 0.7748 - val_loss: 0.1771 - val_accuracy: 0.7430\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1567 - accuracy: 0.7821 - val_loss: 0.1767 - val_accuracy: 0.7470\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1532 - accuracy: 0.7880 - val_loss: 0.1765 - val_accuracy: 0.7490\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 26ms/step - loss: 0.7009 - accuracy: 0.6658 - val_loss: 0.6954 - val_accuracy: 0.6620\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6532 - accuracy: 0.7143 - val_loss: 0.6651 - val_accuracy: 0.7240\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6372 - accuracy: 0.7383 - val_loss: 0.6557 - val_accuracy: 0.7420\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6297 - accuracy: 0.7447 - val_loss: 0.6513 - val_accuracy: 0.7460\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6233 - accuracy: 0.7532 - val_loss: 0.6504 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6182 - accuracy: 0.7570 - val_loss: 0.6503 - val_accuracy: 0.7440\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6132 - accuracy: 0.7614 - val_loss: 0.6480 - val_accuracy: 0.7480\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6066 - accuracy: 0.7713 - val_loss: 0.6506 - val_accuracy: 0.7470\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6038 - accuracy: 0.7708 - val_loss: 0.6536 - val_accuracy: 0.7570\n",
            "Epoch 10/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.5993 - accuracy: 0.7767 - val_loss: 0.6549 - val_accuracy: 0.7490\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 7s 29ms/step - loss: 0.7003 - accuracy: 0.6674 - val_loss: 0.7043 - val_accuracy: 0.6520\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6581 - accuracy: 0.7019 - val_loss: 0.6704 - val_accuracy: 0.7220\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6353 - accuracy: 0.7382 - val_loss: 0.6559 - val_accuracy: 0.7430\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6260 - accuracy: 0.7520 - val_loss: 0.6555 - val_accuracy: 0.7480\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6217 - accuracy: 0.7547 - val_loss: 0.6497 - val_accuracy: 0.7450\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6140 - accuracy: 0.7644 - val_loss: 0.6492 - val_accuracy: 0.7490\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6100 - accuracy: 0.7684 - val_loss: 0.6502 - val_accuracy: 0.7480\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6069 - accuracy: 0.7699 - val_loss: 0.6518 - val_accuracy: 0.7400\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6011 - accuracy: 0.7734 - val_loss: 0.6492 - val_accuracy: 0.7440\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 26ms/step - loss: 0.7043 - accuracy: 0.6512 - val_loss: 0.7064 - val_accuracy: 0.6490\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6623 - accuracy: 0.7008 - val_loss: 0.6622 - val_accuracy: 0.7340\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6359 - accuracy: 0.7397 - val_loss: 0.6535 - val_accuracy: 0.7520\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6275 - accuracy: 0.7505 - val_loss: 0.6524 - val_accuracy: 0.7480\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.6217 - accuracy: 0.7579 - val_loss: 0.6485 - val_accuracy: 0.7440\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.6182 - accuracy: 0.7594 - val_loss: 0.6480 - val_accuracy: 0.7480\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6126 - accuracy: 0.7645 - val_loss: 0.6505 - val_accuracy: 0.7460\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6071 - accuracy: 0.7712 - val_loss: 0.6487 - val_accuracy: 0.7500\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6019 - accuracy: 0.7727 - val_loss: 0.6533 - val_accuracy: 0.7430\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 27ms/step - loss: 0.2201 - accuracy: 0.6658 - val_loss: 0.1951 - val_accuracy: 0.7070\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1811 - accuracy: 0.7351 - val_loss: 0.1824 - val_accuracy: 0.7310\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1729 - accuracy: 0.7544 - val_loss: 0.1745 - val_accuracy: 0.7530\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1655 - accuracy: 0.7653 - val_loss: 0.1734 - val_accuracy: 0.7480\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1604 - accuracy: 0.7739 - val_loss: 0.1740 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1556 - accuracy: 0.7859 - val_loss: 0.1728 - val_accuracy: 0.7560\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1505 - accuracy: 0.7939 - val_loss: 0.1775 - val_accuracy: 0.7400\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1443 - accuracy: 0.8027 - val_loss: 0.1752 - val_accuracy: 0.7490\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1427 - accuracy: 0.8052 - val_loss: 0.1728 - val_accuracy: 0.7440\n",
            "Epoch 10/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1280 - accuracy: 0.8335 - val_loss: 0.1810 - val_accuracy: 0.7550\n",
            "Epoch 11/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1184 - accuracy: 0.8460 - val_loss: 0.1923 - val_accuracy: 0.7420\n",
            "Epoch 12/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1085 - accuracy: 0.8653 - val_loss: 0.2077 - val_accuracy: 0.7160\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 27ms/step - loss: 0.2108 - accuracy: 0.6849 - val_loss: 0.1894 - val_accuracy: 0.7320\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1816 - accuracy: 0.7375 - val_loss: 0.1809 - val_accuracy: 0.7390\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1725 - accuracy: 0.7522 - val_loss: 0.1771 - val_accuracy: 0.7470\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1662 - accuracy: 0.7632 - val_loss: 0.1746 - val_accuracy: 0.7540\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1593 - accuracy: 0.7756 - val_loss: 0.1749 - val_accuracy: 0.7380\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1564 - accuracy: 0.7817 - val_loss: 0.1741 - val_accuracy: 0.7600\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1518 - accuracy: 0.7918 - val_loss: 0.1749 - val_accuracy: 0.7470\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1446 - accuracy: 0.8035 - val_loss: 0.1744 - val_accuracy: 0.7600\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1369 - accuracy: 0.8158 - val_loss: 0.1775 - val_accuracy: 0.7580\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 29ms/step - loss: 0.2130 - accuracy: 0.6837 - val_loss: 0.2034 - val_accuracy: 0.6970\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1830 - accuracy: 0.7351 - val_loss: 0.1856 - val_accuracy: 0.7440\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1725 - accuracy: 0.7544 - val_loss: 0.1759 - val_accuracy: 0.7570\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1652 - accuracy: 0.7648 - val_loss: 0.1745 - val_accuracy: 0.7550\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1625 - accuracy: 0.7725 - val_loss: 0.1764 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1550 - accuracy: 0.7812 - val_loss: 0.1737 - val_accuracy: 0.7590\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1481 - accuracy: 0.7971 - val_loss: 0.1767 - val_accuracy: 0.7430\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1431 - accuracy: 0.8040 - val_loss: 0.1814 - val_accuracy: 0.7490\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1331 - accuracy: 0.8210 - val_loss: 0.1938 - val_accuracy: 0.7180\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 33ms/step - loss: 0.6799 - accuracy: 0.6829 - val_loss: 0.6717 - val_accuracy: 0.7170\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6406 - accuracy: 0.7319 - val_loss: 0.6555 - val_accuracy: 0.7350\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6290 - accuracy: 0.7483 - val_loss: 0.6560 - val_accuracy: 0.7390\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6212 - accuracy: 0.7553 - val_loss: 0.6520 - val_accuracy: 0.7460\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6116 - accuracy: 0.7662 - val_loss: 0.6549 - val_accuracy: 0.7520\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6046 - accuracy: 0.7712 - val_loss: 0.6547 - val_accuracy: 0.7390\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.5902 - accuracy: 0.7815 - val_loss: 0.6636 - val_accuracy: 0.7330\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 26ms/step - loss: 0.6867 - accuracy: 0.6771 - val_loss: 0.6754 - val_accuracy: 0.7230\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6413 - accuracy: 0.7371 - val_loss: 0.6563 - val_accuracy: 0.7310\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.6295 - accuracy: 0.7467 - val_loss: 0.6544 - val_accuracy: 0.7510\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6199 - accuracy: 0.7602 - val_loss: 0.6488 - val_accuracy: 0.7520\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6104 - accuracy: 0.7674 - val_loss: 0.6511 - val_accuracy: 0.7480\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6050 - accuracy: 0.7730 - val_loss: 0.6483 - val_accuracy: 0.7530\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.5959 - accuracy: 0.7801 - val_loss: 0.6628 - val_accuracy: 0.7560\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.5871 - accuracy: 0.7873 - val_loss: 0.6560 - val_accuracy: 0.7340\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.5757 - accuracy: 0.7959 - val_loss: 0.6660 - val_accuracy: 0.7170\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 7s 27ms/step - loss: 0.6752 - accuracy: 0.6906 - val_loss: 0.6674 - val_accuracy: 0.7310\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6381 - accuracy: 0.7367 - val_loss: 0.6576 - val_accuracy: 0.7430\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.6262 - accuracy: 0.7520 - val_loss: 0.6566 - val_accuracy: 0.7430\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6169 - accuracy: 0.7618 - val_loss: 0.6581 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6111 - accuracy: 0.7641 - val_loss: 0.6501 - val_accuracy: 0.7460\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6027 - accuracy: 0.7713 - val_loss: 0.6502 - val_accuracy: 0.7370\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.5920 - accuracy: 0.7794 - val_loss: 0.6727 - val_accuracy: 0.7490\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.5820 - accuracy: 0.7914 - val_loss: 0.6593 - val_accuracy: 0.7310\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 8s 49ms/step - loss: 0.2077 - accuracy: 0.6912 - val_loss: 0.1814 - val_accuracy: 0.7360\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1755 - accuracy: 0.7516 - val_loss: 0.1795 - val_accuracy: 0.7440\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.1661 - accuracy: 0.7640 - val_loss: 0.1724 - val_accuracy: 0.7550\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.1576 - accuracy: 0.7823 - val_loss: 0.1703 - val_accuracy: 0.7640\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.1484 - accuracy: 0.7968 - val_loss: 0.1799 - val_accuracy: 0.7370\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.1394 - accuracy: 0.8136 - val_loss: 0.1837 - val_accuracy: 0.7470\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.1250 - accuracy: 0.8326 - val_loss: 0.1810 - val_accuracy: 0.7480\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 6s 26ms/step - loss: 0.2063 - accuracy: 0.6961 - val_loss: 0.1995 - val_accuracy: 0.7330\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1782 - accuracy: 0.7487 - val_loss: 0.1763 - val_accuracy: 0.7430\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1667 - accuracy: 0.7641 - val_loss: 0.1748 - val_accuracy: 0.7410\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1591 - accuracy: 0.7787 - val_loss: 0.1717 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1503 - accuracy: 0.7943 - val_loss: 0.1790 - val_accuracy: 0.7330\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1392 - accuracy: 0.8114 - val_loss: 0.1818 - val_accuracy: 0.7510\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1264 - accuracy: 0.8315 - val_loss: 0.1892 - val_accuracy: 0.7410\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 6s 34ms/step - loss: 0.2010 - accuracy: 0.7056 - val_loss: 0.1841 - val_accuracy: 0.7360\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1741 - accuracy: 0.7518 - val_loss: 0.1747 - val_accuracy: 0.7460\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1667 - accuracy: 0.7642 - val_loss: 0.1708 - val_accuracy: 0.7550\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1574 - accuracy: 0.7788 - val_loss: 0.1726 - val_accuracy: 0.7440\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1491 - accuracy: 0.7945 - val_loss: 0.1732 - val_accuracy: 0.7590\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1354 - accuracy: 0.8172 - val_loss: 0.1941 - val_accuracy: 0.7310\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 6s 26ms/step - loss: 0.6720 - accuracy: 0.6962 - val_loss: 0.6612 - val_accuracy: 0.7450\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.6310 - accuracy: 0.7479 - val_loss: 0.6593 - val_accuracy: 0.7340\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6165 - accuracy: 0.7625 - val_loss: 0.6471 - val_accuracy: 0.7600\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6049 - accuracy: 0.7711 - val_loss: 0.6502 - val_accuracy: 0.7460\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.5861 - accuracy: 0.7871 - val_loss: 0.6553 - val_accuracy: 0.7540\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.5634 - accuracy: 0.8048 - val_loss: 0.6737 - val_accuracy: 0.7100\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 37ms/step - loss: 0.6721 - accuracy: 0.6902 - val_loss: 0.6608 - val_accuracy: 0.7300\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6346 - accuracy: 0.7406 - val_loss: 0.6514 - val_accuracy: 0.7450\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6201 - accuracy: 0.7569 - val_loss: 0.6639 - val_accuracy: 0.7640\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6093 - accuracy: 0.7697 - val_loss: 0.6487 - val_accuracy: 0.7480\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.5921 - accuracy: 0.7852 - val_loss: 0.6563 - val_accuracy: 0.7390\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.5717 - accuracy: 0.7975 - val_loss: 0.6743 - val_accuracy: 0.7220\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.5453 - accuracy: 0.8239 - val_loss: 0.7101 - val_accuracy: 0.7260\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 26ms/step - loss: 0.6647 - accuracy: 0.7054 - val_loss: 0.6605 - val_accuracy: 0.7370\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6325 - accuracy: 0.7496 - val_loss: 0.6504 - val_accuracy: 0.7500\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6182 - accuracy: 0.7606 - val_loss: 0.6474 - val_accuracy: 0.7680\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6037 - accuracy: 0.7752 - val_loss: 0.6518 - val_accuracy: 0.7520\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.5876 - accuracy: 0.7880 - val_loss: 0.6531 - val_accuracy: 0.7350\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.5652 - accuracy: 0.8068 - val_loss: 0.7012 - val_accuracy: 0.7420\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 6s 14ms/step - loss: 0.2006 - accuracy: 0.7017 - val_loss: 0.1837 - val_accuracy: 0.7350\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1796 - accuracy: 0.7426 - val_loss: 0.1791 - val_accuracy: 0.7500\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1717 - accuracy: 0.7570 - val_loss: 0.1799 - val_accuracy: 0.7450\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 13ms/step - loss: 0.1659 - accuracy: 0.7681 - val_loss: 0.1782 - val_accuracy: 0.7460\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 13ms/step - loss: 0.1627 - accuracy: 0.7700 - val_loss: 0.1795 - val_accuracy: 0.7540\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1553 - accuracy: 0.7828 - val_loss: 0.1809 - val_accuracy: 0.7390\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1492 - accuracy: 0.7929 - val_loss: 0.1854 - val_accuracy: 0.7490\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 9s 27ms/step - loss: 0.2036 - accuracy: 0.6940 - val_loss: 0.1842 - val_accuracy: 0.7330\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 13ms/step - loss: 0.1814 - accuracy: 0.7394 - val_loss: 0.1794 - val_accuracy: 0.7420\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1749 - accuracy: 0.7528 - val_loss: 0.1860 - val_accuracy: 0.7380\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.1688 - accuracy: 0.7642 - val_loss: 0.1803 - val_accuracy: 0.7390\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 4s 21ms/step - loss: 0.1631 - accuracy: 0.7696 - val_loss: 0.1781 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 5s 25ms/step - loss: 0.1562 - accuracy: 0.7804 - val_loss: 0.1793 - val_accuracy: 0.7610\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 4s 18ms/step - loss: 0.1524 - accuracy: 0.7873 - val_loss: 0.1787 - val_accuracy: 0.7530\n",
            "Epoch 8/50\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1444 - accuracy: 0.8024 - val_loss: 0.1829 - val_accuracy: 0.7570\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 14ms/step - loss: 0.2035 - accuracy: 0.6996 - val_loss: 0.1847 - val_accuracy: 0.7340\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1798 - accuracy: 0.7387 - val_loss: 0.1763 - val_accuracy: 0.7500\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1736 - accuracy: 0.7505 - val_loss: 0.1781 - val_accuracy: 0.7490\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.1667 - accuracy: 0.7632 - val_loss: 0.1734 - val_accuracy: 0.7590\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 0.1623 - accuracy: 0.7726 - val_loss: 0.1786 - val_accuracy: 0.7400\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.1565 - accuracy: 0.7790 - val_loss: 0.1769 - val_accuracy: 0.7560\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1509 - accuracy: 0.7886 - val_loss: 0.1806 - val_accuracy: 0.7540\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 15ms/step - loss: 0.7001 - accuracy: 0.6596 - val_loss: 0.6854 - val_accuracy: 0.6920\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.6652 - accuracy: 0.7086 - val_loss: 0.6812 - val_accuracy: 0.6930\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.6419 - accuracy: 0.7304 - val_loss: 0.6695 - val_accuracy: 0.7380\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.7203 - accuracy: 0.6301 - val_loss: 0.7315 - val_accuracy: 0.6460\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6667 - accuracy: 0.6955 - val_loss: 0.6748 - val_accuracy: 0.7180\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.0010 - accuracy: 0.5013 - val_loss: 0.7236 - val_accuracy: 0.6240\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 14ms/step - loss: 0.7429 - accuracy: 0.6449 - val_loss: 0.7122 - val_accuracy: 0.6390\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6617 - accuracy: 0.7096 - val_loss: 0.6714 - val_accuracy: 0.7250\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6481 - accuracy: 0.7297 - val_loss: 0.6658 - val_accuracy: 0.7330\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6366 - accuracy: 0.7368 - val_loss: 0.6870 - val_accuracy: 0.7370\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.6271 - accuracy: 0.7507 - val_loss: 0.6622 - val_accuracy: 0.7330\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 4s 19ms/step - loss: 0.6198 - accuracy: 0.7571 - val_loss: 0.6808 - val_accuracy: 0.7250\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 4s 21ms/step - loss: 0.6192 - accuracy: 0.7559 - val_loss: 0.6730 - val_accuracy: 0.7160\n",
            "Epoch 8/50\n",
            "192/192 [==============================] - 4s 20ms/step - loss: 0.6500 - accuracy: 0.7260 - val_loss: 0.6764 - val_accuracy: 0.7090\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 14ms/step - loss: 0.7251 - accuracy: 0.6636 - val_loss: 0.6880 - val_accuracy: 0.6730\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6595 - accuracy: 0.7134 - val_loss: 0.6752 - val_accuracy: 0.6980\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6485 - accuracy: 0.7288 - val_loss: 0.6722 - val_accuracy: 0.7210\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6348 - accuracy: 0.7418 - val_loss: 0.6616 - val_accuracy: 0.7330\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.6263 - accuracy: 0.7550 - val_loss: 0.6720 - val_accuracy: 0.7470\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.6226 - accuracy: 0.7578 - val_loss: 0.7140 - val_accuracy: 0.7380\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.6158 - accuracy: 0.7608 - val_loss: 0.7375 - val_accuracy: 0.7290\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 10s 26ms/step - loss: 0.2009 - accuracy: 0.7092 - val_loss: 0.1918 - val_accuracy: 0.7270\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 4s 20ms/step - loss: 0.1766 - accuracy: 0.7481 - val_loss: 0.1772 - val_accuracy: 0.7510\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 4s 22ms/step - loss: 0.1671 - accuracy: 0.7623 - val_loss: 0.1746 - val_accuracy: 0.7480\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 6s 30ms/step - loss: 0.1603 - accuracy: 0.7769 - val_loss: 0.1752 - val_accuracy: 0.7530\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 4s 21ms/step - loss: 0.1533 - accuracy: 0.7855 - val_loss: 0.1785 - val_accuracy: 0.7520\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 4s 20ms/step - loss: 0.1428 - accuracy: 0.8053 - val_loss: 0.1808 - val_accuracy: 0.7520\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 18ms/step - loss: 0.2009 - accuracy: 0.7051 - val_loss: 0.1795 - val_accuracy: 0.7440\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1760 - accuracy: 0.7509 - val_loss: 0.1754 - val_accuracy: 0.7650\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 13ms/step - loss: 0.1691 - accuracy: 0.7597 - val_loss: 0.1899 - val_accuracy: 0.7280\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.1628 - accuracy: 0.7738 - val_loss: 0.1773 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1545 - accuracy: 0.7832 - val_loss: 0.1795 - val_accuracy: 0.7560\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 19ms/step - loss: 0.1996 - accuracy: 0.7039 - val_loss: 0.1843 - val_accuracy: 0.7370\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.1776 - accuracy: 0.7478 - val_loss: 0.1747 - val_accuracy: 0.7490\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1678 - accuracy: 0.7603 - val_loss: 0.1774 - val_accuracy: 0.7490\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1611 - accuracy: 0.7723 - val_loss: 0.1823 - val_accuracy: 0.7310\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1533 - accuracy: 0.7850 - val_loss: 0.1819 - val_accuracy: 0.7450\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 14ms/step - loss: 0.6904 - accuracy: 0.6721 - val_loss: 0.6768 - val_accuracy: 0.6910\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6688 - accuracy: 0.6972 - val_loss: 0.6701 - val_accuracy: 0.7110\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6474 - accuracy: 0.7367 - val_loss: 0.6865 - val_accuracy: 0.7450\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6414 - accuracy: 0.7317 - val_loss: 0.7035 - val_accuracy: 0.6530\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6419 - accuracy: 0.7433 - val_loss: 0.6836 - val_accuracy: 0.7430\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 14ms/step - loss: 0.6966 - accuracy: 0.6774 - val_loss: 0.6757 - val_accuracy: 0.6970\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6779 - accuracy: 0.6902 - val_loss: 0.6660 - val_accuracy: 0.7230\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6555 - accuracy: 0.7321 - val_loss: 0.6623 - val_accuracy: 0.7220\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6297 - accuracy: 0.7480 - val_loss: 0.6712 - val_accuracy: 0.7420\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.6315 - accuracy: 0.7484 - val_loss: 0.6690 - val_accuracy: 0.7440\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 0.6204 - accuracy: 0.7604 - val_loss: 0.6788 - val_accuracy: 0.7490\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 11s 15ms/step - loss: 0.7243 - accuracy: 0.6605 - val_loss: 0.6811 - val_accuracy: 0.6950\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6569 - accuracy: 0.7188 - val_loss: 0.6578 - val_accuracy: 0.7240\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.6393 - accuracy: 0.7395 - val_loss: 0.6697 - val_accuracy: 0.7210\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.6391 - accuracy: 0.7375 - val_loss: 0.6568 - val_accuracy: 0.7370\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.6312 - accuracy: 0.7471 - val_loss: 0.6654 - val_accuracy: 0.7400\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 13ms/step - loss: 0.6278 - accuracy: 0.7511 - val_loss: 0.6646 - val_accuracy: 0.7510\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6205 - accuracy: 0.7557 - val_loss: 0.6657 - val_accuracy: 0.7420\n",
            "32/32 [==============================] - 2s 5ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 14ms/step - loss: 0.2048 - accuracy: 0.7069 - val_loss: 0.1815 - val_accuracy: 0.7470\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1724 - accuracy: 0.7569 - val_loss: 0.1868 - val_accuracy: 0.7260\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1617 - accuracy: 0.7734 - val_loss: 0.1751 - val_accuracy: 0.7550\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1517 - accuracy: 0.7890 - val_loss: 0.1780 - val_accuracy: 0.7380\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.1356 - accuracy: 0.8179 - val_loss: 0.1923 - val_accuracy: 0.7340\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 0.1197 - accuracy: 0.8417 - val_loss: 0.2032 - val_accuracy: 0.7300\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 8s 16ms/step - loss: 0.1972 - accuracy: 0.7123 - val_loss: 0.1831 - val_accuracy: 0.7390\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1723 - accuracy: 0.7516 - val_loss: 0.1779 - val_accuracy: 0.7410\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1618 - accuracy: 0.7708 - val_loss: 0.1727 - val_accuracy: 0.7560\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1505 - accuracy: 0.7916 - val_loss: 0.1798 - val_accuracy: 0.7410\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1371 - accuracy: 0.8129 - val_loss: 0.1788 - val_accuracy: 0.7400\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.1210 - accuracy: 0.8405 - val_loss: 0.1998 - val_accuracy: 0.7300\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 19ms/step - loss: 0.1996 - accuracy: 0.7136 - val_loss: 0.1793 - val_accuracy: 0.7400\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 12ms/step - loss: 0.1737 - accuracy: 0.7570 - val_loss: 0.1744 - val_accuracy: 0.7540\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1619 - accuracy: 0.7736 - val_loss: 0.1736 - val_accuracy: 0.7460\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1525 - accuracy: 0.7873 - val_loss: 0.1825 - val_accuracy: 0.7490\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1393 - accuracy: 0.8083 - val_loss: 0.1836 - val_accuracy: 0.7490\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.1216 - accuracy: 0.8399 - val_loss: 0.1977 - val_accuracy: 0.7450\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 17ms/step - loss: 0.7505 - accuracy: 0.6837 - val_loss: 0.6738 - val_accuracy: 0.7200\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.6452 - accuracy: 0.7382 - val_loss: 0.6650 - val_accuracy: 0.7430\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 0.6291 - accuracy: 0.7565 - val_loss: 0.6538 - val_accuracy: 0.7450\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6359 - accuracy: 0.7531 - val_loss: 0.6501 - val_accuracy: 0.7460\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6196 - accuracy: 0.7667 - val_loss: 0.6662 - val_accuracy: 0.7410\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6254 - accuracy: 0.7503 - val_loss: 0.7143 - val_accuracy: 0.7540\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6166 - accuracy: 0.7743 - val_loss: 0.6833 - val_accuracy: 0.7490\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 7ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 7s 14ms/step - loss: 5.1052 - accuracy: 0.6570 - val_loss: 5.6736 - val_accuracy: 0.6480\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.3309 - accuracy: 0.6690 - val_loss: 5.6736 - val_accuracy: 0.6480\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.3306 - accuracy: 0.6693 - val_loss: 5.6736 - val_accuracy: 0.6480\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 11ms/step - loss: 5.3306 - accuracy: 0.6693 - val_loss: 5.6736 - val_accuracy: 0.6480\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "192/192 [==============================] - 6s 14ms/step - loss: 0.8148 - accuracy: 0.6165 - val_loss: 1.1903 - val_accuracy: 0.6000\n",
            "Epoch 2/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.7383 - accuracy: 0.6498 - val_loss: 0.6691 - val_accuracy: 0.7230\n",
            "Epoch 3/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6600 - accuracy: 0.7143 - val_loss: 0.6622 - val_accuracy: 0.7410\n",
            "Epoch 4/50\n",
            "192/192 [==============================] - 2s 13ms/step - loss: 0.6395 - accuracy: 0.7516 - val_loss: 0.6573 - val_accuracy: 0.7510\n",
            "Epoch 5/50\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 0.6290 - accuracy: 0.7564 - val_loss: 0.6789 - val_accuracy: 0.7530\n",
            "Epoch 6/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6483 - accuracy: 0.7240 - val_loss: 0.6505 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6209 - accuracy: 0.7640 - val_loss: 0.6536 - val_accuracy: 0.7480\n",
            "Epoch 8/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6458 - accuracy: 0.7217 - val_loss: 0.6973 - val_accuracy: 0.7030\n",
            "Epoch 9/50\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.6211 - accuracy: 0.7634 - val_loss: 0.7287 - val_accuracy: 0.7570\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 7s 19ms/step - loss: 0.2107 - accuracy: 0.6815 - val_loss: 0.1961 - val_accuracy: 0.7080\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1848 - accuracy: 0.7337 - val_loss: 0.1927 - val_accuracy: 0.7310\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1760 - accuracy: 0.7464 - val_loss: 0.1839 - val_accuracy: 0.7330\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.7600 - val_loss: 0.1843 - val_accuracy: 0.7340\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1651 - accuracy: 0.7660 - val_loss: 0.1790 - val_accuracy: 0.7470\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1606 - accuracy: 0.7702 - val_loss: 0.1818 - val_accuracy: 0.7330\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1565 - accuracy: 0.7776 - val_loss: 0.1827 - val_accuracy: 0.7500\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1513 - accuracy: 0.7886 - val_loss: 0.1863 - val_accuracy: 0.7340\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 6s 17ms/step - loss: 0.2142 - accuracy: 0.6804 - val_loss: 0.1941 - val_accuracy: 0.7050\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1861 - accuracy: 0.7317 - val_loss: 0.1825 - val_accuracy: 0.7410\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1755 - accuracy: 0.7497 - val_loss: 0.1827 - val_accuracy: 0.7330\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1695 - accuracy: 0.7590 - val_loss: 0.1796 - val_accuracy: 0.7470\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1644 - accuracy: 0.7667 - val_loss: 0.1804 - val_accuracy: 0.7390\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1620 - accuracy: 0.7712 - val_loss: 0.1778 - val_accuracy: 0.7530\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1566 - accuracy: 0.7777 - val_loss: 0.1772 - val_accuracy: 0.7460\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1518 - accuracy: 0.7884 - val_loss: 0.1797 - val_accuracy: 0.7600\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1474 - accuracy: 0.7932 - val_loss: 0.1835 - val_accuracy: 0.7470\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1387 - accuracy: 0.8104 - val_loss: 0.1869 - val_accuracy: 0.7360\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 6s 18ms/step - loss: 0.2098 - accuracy: 0.6837 - val_loss: 0.1936 - val_accuracy: 0.7100\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1843 - accuracy: 0.7340 - val_loss: 0.1911 - val_accuracy: 0.7260\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1761 - accuracy: 0.7493 - val_loss: 0.1805 - val_accuracy: 0.7490\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1700 - accuracy: 0.7583 - val_loss: 0.1805 - val_accuracy: 0.7420\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1661 - accuracy: 0.7667 - val_loss: 0.1789 - val_accuracy: 0.7510\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.7711 - val_loss: 0.1844 - val_accuracy: 0.7210\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1595 - accuracy: 0.7744 - val_loss: 0.1785 - val_accuracy: 0.7510\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1541 - accuracy: 0.7845 - val_loss: 0.1853 - val_accuracy: 0.7270\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1467 - accuracy: 0.7984 - val_loss: 0.1842 - val_accuracy: 0.7500\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1416 - accuracy: 0.8068 - val_loss: 0.1877 - val_accuracy: 0.7210\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 7s 18ms/step - loss: 5.2115 - accuracy: 0.6696 - val_loss: 1.1906 - val_accuracy: 0.5730\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.7293 - accuracy: 0.6258 - val_loss: 0.6951 - val_accuracy: 0.6650\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6683 - accuracy: 0.6978 - val_loss: 0.6683 - val_accuracy: 0.7080\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6586 - accuracy: 0.7109 - val_loss: 0.6633 - val_accuracy: 0.7240\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6433 - accuracy: 0.7387 - val_loss: 0.6572 - val_accuracy: 0.7300\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6341 - accuracy: 0.7462 - val_loss: 0.6529 - val_accuracy: 0.7390\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6344 - accuracy: 0.7453 - val_loss: 0.7203 - val_accuracy: 0.6730\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6315 - accuracy: 0.7471 - val_loss: 0.6516 - val_accuracy: 0.7580\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6807 - accuracy: 0.6806 - val_loss: 0.6796 - val_accuracy: 0.7050\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6308 - accuracy: 0.7453 - val_loss: 0.6848 - val_accuracy: 0.7390\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6152 - accuracy: 0.7617 - val_loss: 0.7338 - val_accuracy: 0.6300\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 8s 18ms/step - loss: 0.8298 - accuracy: 0.6012 - val_loss: 0.7225 - val_accuracy: 0.6480\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6883 - accuracy: 0.6709 - val_loss: 0.7090 - val_accuracy: 0.6540\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6736 - accuracy: 0.6824 - val_loss: 0.6878 - val_accuracy: 0.6810\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6556 - accuracy: 0.7161 - val_loss: 0.6822 - val_accuracy: 0.7320\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6398 - accuracy: 0.7372 - val_loss: 0.6749 - val_accuracy: 0.7390\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6393 - accuracy: 0.7296 - val_loss: 0.6720 - val_accuracy: 0.7130\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.6295 - accuracy: 0.7489 - val_loss: 0.6649 - val_accuracy: 0.7410\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6187 - accuracy: 0.7564 - val_loss: 0.6628 - val_accuracy: 0.7450\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6127 - accuracy: 0.7649 - val_loss: 0.6627 - val_accuracy: 0.7490\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6071 - accuracy: 0.7671 - val_loss: 0.6677 - val_accuracy: 0.7530\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6019 - accuracy: 0.7734 - val_loss: 0.7199 - val_accuracy: 0.7480\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6012 - accuracy: 0.7727 - val_loss: 0.6599 - val_accuracy: 0.7360\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6032 - accuracy: 0.7766 - val_loss: 0.6972 - val_accuracy: 0.7370\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.5948 - accuracy: 0.7799 - val_loss: 0.6931 - val_accuracy: 0.7460\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6007 - accuracy: 0.7809 - val_loss: 0.7111 - val_accuracy: 0.7390\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.7154 - accuracy: 0.6431 - val_loss: 0.6934 - val_accuracy: 0.6670\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6714 - accuracy: 0.6891 - val_loss: 0.6935 - val_accuracy: 0.6560\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6583 - accuracy: 0.7087 - val_loss: 0.6652 - val_accuracy: 0.7200\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6517 - accuracy: 0.7208 - val_loss: 0.6832 - val_accuracy: 0.7130\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6450 - accuracy: 0.7251 - val_loss: 0.8132 - val_accuracy: 0.7280\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.7417 - val_loss: 0.6700 - val_accuracy: 0.7410\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.2094 - accuracy: 0.6886 - val_loss: 0.1884 - val_accuracy: 0.7140\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1805 - accuracy: 0.7409 - val_loss: 0.1782 - val_accuracy: 0.7420\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1701 - accuracy: 0.7584 - val_loss: 0.1757 - val_accuracy: 0.7510\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1637 - accuracy: 0.7673 - val_loss: 0.1747 - val_accuracy: 0.7520\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1580 - accuracy: 0.7752 - val_loss: 0.1785 - val_accuracy: 0.7590\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1497 - accuracy: 0.7912 - val_loss: 0.1780 - val_accuracy: 0.7470\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1413 - accuracy: 0.8044 - val_loss: 0.1889 - val_accuracy: 0.7290\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.2097 - accuracy: 0.6952 - val_loss: 0.1846 - val_accuracy: 0.7340\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1781 - accuracy: 0.7449 - val_loss: 0.1778 - val_accuracy: 0.7450\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1705 - accuracy: 0.7594 - val_loss: 0.1760 - val_accuracy: 0.7570\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1643 - accuracy: 0.7666 - val_loss: 0.1748 - val_accuracy: 0.7560\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1581 - accuracy: 0.7770 - val_loss: 0.1801 - val_accuracy: 0.7320\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1515 - accuracy: 0.7847 - val_loss: 0.1832 - val_accuracy: 0.7370\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1436 - accuracy: 0.8011 - val_loss: 0.1795 - val_accuracy: 0.7440\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.2004 - accuracy: 0.7002 - val_loss: 0.1832 - val_accuracy: 0.7240\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1834 - accuracy: 0.7344 - val_loss: 0.1834 - val_accuracy: 0.7310\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1714 - accuracy: 0.7570 - val_loss: 0.1775 - val_accuracy: 0.7570\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1639 - accuracy: 0.7679 - val_loss: 0.1813 - val_accuracy: 0.7390\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1587 - accuracy: 0.7775 - val_loss: 0.1813 - val_accuracy: 0.7650\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1507 - accuracy: 0.7880 - val_loss: 0.1789 - val_accuracy: 0.7560\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 8ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.7357 - accuracy: 0.6690 - val_loss: 0.6777 - val_accuracy: 0.7050\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6574 - accuracy: 0.7107 - val_loss: 0.6686 - val_accuracy: 0.7220\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6516 - accuracy: 0.7342 - val_loss: 0.6846 - val_accuracy: 0.7290\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6382 - accuracy: 0.7409 - val_loss: 0.6583 - val_accuracy: 0.7260\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6359 - accuracy: 0.7440 - val_loss: 0.6819 - val_accuracy: 0.7450\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6231 - accuracy: 0.7588 - val_loss: 0.6702 - val_accuracy: 0.7420\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6330 - accuracy: 0.7382 - val_loss: 0.6611 - val_accuracy: 0.7350\n",
            "32/32 [==============================] - 1s 7ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.7410 - accuracy: 0.6423 - val_loss: 0.6923 - val_accuracy: 0.6760\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6662 - accuracy: 0.7032 - val_loss: 0.6896 - val_accuracy: 0.7230\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6681 - accuracy: 0.6922 - val_loss: 0.6829 - val_accuracy: 0.6790\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6438 - accuracy: 0.7270 - val_loss: 0.6631 - val_accuracy: 0.7300\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6423 - accuracy: 0.7319 - val_loss: 0.6598 - val_accuracy: 0.7370\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6240 - accuracy: 0.7520 - val_loss: 0.6604 - val_accuracy: 0.7410\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6259 - accuracy: 0.7538 - val_loss: 0.6890 - val_accuracy: 0.7510\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6192 - accuracy: 0.7600 - val_loss: 0.6664 - val_accuracy: 0.7420\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 7ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.7038 - accuracy: 0.6603 - val_loss: 0.6790 - val_accuracy: 0.7000\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6534 - accuracy: 0.7187 - val_loss: 0.6877 - val_accuracy: 0.6920\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6775 - accuracy: 0.6876 - val_loss: 0.6912 - val_accuracy: 0.7030\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6424 - accuracy: 0.7353 - val_loss: 0.6599 - val_accuracy: 0.7370\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.6377 - accuracy: 0.7389 - val_loss: 0.6691 - val_accuracy: 0.7400\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6300 - accuracy: 0.7508 - val_loss: 0.6920 - val_accuracy: 0.7220\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.6217 - accuracy: 0.7581 - val_loss: 0.6690 - val_accuracy: 0.7510\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.2070 - accuracy: 0.6984 - val_loss: 0.1849 - val_accuracy: 0.7440\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1748 - accuracy: 0.7490 - val_loss: 0.1733 - val_accuracy: 0.7510\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1632 - accuracy: 0.7685 - val_loss: 0.1717 - val_accuracy: 0.7610\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1537 - accuracy: 0.7844 - val_loss: 0.1824 - val_accuracy: 0.7420\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1425 - accuracy: 0.8030 - val_loss: 0.1827 - val_accuracy: 0.7450\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1254 - accuracy: 0.8318 - val_loss: 0.1952 - val_accuracy: 0.7350\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 18ms/step - loss: 0.1996 - accuracy: 0.7158 - val_loss: 0.1838 - val_accuracy: 0.7260\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1731 - accuracy: 0.7512 - val_loss: 0.1757 - val_accuracy: 0.7480\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1625 - accuracy: 0.7719 - val_loss: 0.1742 - val_accuracy: 0.7560\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1524 - accuracy: 0.7905 - val_loss: 0.1755 - val_accuracy: 0.7520\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1415 - accuracy: 0.8047 - val_loss: 0.1814 - val_accuracy: 0.7540\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1262 - accuracy: 0.8309 - val_loss: 0.1950 - val_accuracy: 0.7330\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 6s 18ms/step - loss: 0.2045 - accuracy: 0.6962 - val_loss: 0.1783 - val_accuracy: 0.7480\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1745 - accuracy: 0.7556 - val_loss: 0.1737 - val_accuracy: 0.7590\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.1659 - accuracy: 0.7653 - val_loss: 0.1723 - val_accuracy: 0.7610\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.1563 - accuracy: 0.7802 - val_loss: 0.1742 - val_accuracy: 0.7650\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.1437 - accuracy: 0.8041 - val_loss: 0.1792 - val_accuracy: 0.7570\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1288 - accuracy: 0.8247 - val_loss: 0.1991 - val_accuracy: 0.7270\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 19ms/step - loss: 0.7647 - accuracy: 0.6484 - val_loss: 0.6790 - val_accuracy: 0.7050\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6750 - accuracy: 0.6921 - val_loss: 0.6833 - val_accuracy: 0.7070\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.6484 - accuracy: 0.7308 - val_loss: 0.6674 - val_accuracy: 0.7470\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6339 - accuracy: 0.7422 - val_loss: 0.6578 - val_accuracy: 0.7520\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6254 - accuracy: 0.7577 - val_loss: 0.6638 - val_accuracy: 0.7590\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6241 - accuracy: 0.7578 - val_loss: 0.6731 - val_accuracy: 0.7550\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6138 - accuracy: 0.7676 - val_loss: 0.6902 - val_accuracy: 0.6620\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 10s 25ms/step - loss: 0.6969 - accuracy: 0.6603 - val_loss: 0.7014 - val_accuracy: 0.6680\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 15ms/step - loss: 0.6491 - accuracy: 0.7289 - val_loss: 0.6767 - val_accuracy: 0.7250\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 15ms/step - loss: 0.6289 - accuracy: 0.7517 - val_loss: 0.6643 - val_accuracy: 0.7450\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.6312 - accuracy: 0.7574 - val_loss: 0.6736 - val_accuracy: 0.7530\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6461 - accuracy: 0.7497 - val_loss: 0.6979 - val_accuracy: 0.6540\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6305 - accuracy: 0.7545 - val_loss: 0.6681 - val_accuracy: 0.7380\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 6s 20ms/step - loss: 0.7658 - accuracy: 0.5954 - val_loss: 0.6997 - val_accuracy: 0.6570\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6700 - accuracy: 0.6933 - val_loss: 0.6914 - val_accuracy: 0.6820\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6672 - accuracy: 0.6923 - val_loss: 0.6852 - val_accuracy: 0.6810\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6470 - accuracy: 0.7233 - val_loss: 0.6692 - val_accuracy: 0.7140\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.6364 - accuracy: 0.7479 - val_loss: 0.6545 - val_accuracy: 0.7440\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6230 - accuracy: 0.7625 - val_loss: 0.7401 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6155 - accuracy: 0.7675 - val_loss: 0.6837 - val_accuracy: 0.7370\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.6992 - accuracy: 0.6498 - val_loss: 0.6945 - val_accuracy: 0.6770\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 29ms/step - loss: 0.2260 - accuracy: 0.6681 - val_loss: 0.2026 - val_accuracy: 0.6860\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1896 - accuracy: 0.7219 - val_loss: 0.1836 - val_accuracy: 0.7360\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1768 - accuracy: 0.7451 - val_loss: 0.1804 - val_accuracy: 0.7500\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1715 - accuracy: 0.7556 - val_loss: 0.1805 - val_accuracy: 0.7380\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 17ms/step - loss: 0.1687 - accuracy: 0.7600 - val_loss: 0.1795 - val_accuracy: 0.7460\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1664 - accuracy: 0.7601 - val_loss: 0.1793 - val_accuracy: 0.7510\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1614 - accuracy: 0.7717 - val_loss: 0.1800 - val_accuracy: 0.7440\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1571 - accuracy: 0.7801 - val_loss: 0.1781 - val_accuracy: 0.7400\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1527 - accuracy: 0.7851 - val_loss: 0.1833 - val_accuracy: 0.7370\n",
            "Epoch 10/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1480 - accuracy: 0.7928 - val_loss: 0.1833 - val_accuracy: 0.7410\n",
            "Epoch 11/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1441 - accuracy: 0.7990 - val_loss: 0.1842 - val_accuracy: 0.7470\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 27ms/step - loss: 0.2300 - accuracy: 0.6615 - val_loss: 0.2056 - val_accuracy: 0.6860\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1922 - accuracy: 0.7157 - val_loss: 0.1892 - val_accuracy: 0.7230\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1798 - accuracy: 0.7434 - val_loss: 0.1823 - val_accuracy: 0.7490\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1732 - accuracy: 0.7530 - val_loss: 0.1820 - val_accuracy: 0.7360\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 17ms/step - loss: 0.1701 - accuracy: 0.7583 - val_loss: 0.1829 - val_accuracy: 0.7430\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 17ms/step - loss: 0.1668 - accuracy: 0.7642 - val_loss: 0.1871 - val_accuracy: 0.7380\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1634 - accuracy: 0.7676 - val_loss: 0.1780 - val_accuracy: 0.7550\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1590 - accuracy: 0.7730 - val_loss: 0.1768 - val_accuracy: 0.7600\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1548 - accuracy: 0.7818 - val_loss: 0.1799 - val_accuracy: 0.7460\n",
            "Epoch 10/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1509 - accuracy: 0.7875 - val_loss: 0.1809 - val_accuracy: 0.7490\n",
            "Epoch 11/50\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1472 - accuracy: 0.7926 - val_loss: 0.1828 - val_accuracy: 0.7430\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 27ms/step - loss: 0.2161 - accuracy: 0.6719 - val_loss: 0.2034 - val_accuracy: 0.6910\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1901 - accuracy: 0.7208 - val_loss: 0.1881 - val_accuracy: 0.7290\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1801 - accuracy: 0.7425 - val_loss: 0.1826 - val_accuracy: 0.7470\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1744 - accuracy: 0.7524 - val_loss: 0.1812 - val_accuracy: 0.7470\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1693 - accuracy: 0.7595 - val_loss: 0.1804 - val_accuracy: 0.7450\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1654 - accuracy: 0.7635 - val_loss: 0.1814 - val_accuracy: 0.7380\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1622 - accuracy: 0.7701 - val_loss: 0.1819 - val_accuracy: 0.7390\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1585 - accuracy: 0.7796 - val_loss: 0.1841 - val_accuracy: 0.7410\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 29ms/step - loss: 0.7913 - accuracy: 0.5893 - val_loss: 0.7270 - val_accuracy: 0.6380\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6833 - accuracy: 0.6688 - val_loss: 0.6990 - val_accuracy: 0.6500\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.6660 - accuracy: 0.6946 - val_loss: 0.6843 - val_accuracy: 0.6890\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6559 - accuracy: 0.7102 - val_loss: 0.6769 - val_accuracy: 0.7040\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.6469 - accuracy: 0.7255 - val_loss: 0.6691 - val_accuracy: 0.7080\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6400 - accuracy: 0.7326 - val_loss: 0.6700 - val_accuracy: 0.7190\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.6352 - accuracy: 0.7407 - val_loss: 0.7063 - val_accuracy: 0.7350\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6373 - accuracy: 0.7347 - val_loss: 0.6990 - val_accuracy: 0.7180\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 27ms/step - loss: 0.9857 - accuracy: 0.5775 - val_loss: 0.7522 - val_accuracy: 0.5750\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.7046 - accuracy: 0.6502 - val_loss: 0.7258 - val_accuracy: 0.6250\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6937 - accuracy: 0.6676 - val_loss: 0.7161 - val_accuracy: 0.6370\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6841 - accuracy: 0.6742 - val_loss: 0.7075 - val_accuracy: 0.6500\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6750 - accuracy: 0.6845 - val_loss: 0.6964 - val_accuracy: 0.6590\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6644 - accuracy: 0.6949 - val_loss: 0.6862 - val_accuracy: 0.6700\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6502 - accuracy: 0.7195 - val_loss: 0.6595 - val_accuracy: 0.7200\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6363 - accuracy: 0.7396 - val_loss: 0.6498 - val_accuracy: 0.7450\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.6336 - accuracy: 0.7467 - val_loss: 0.6533 - val_accuracy: 0.7440\n",
            "Epoch 10/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6220 - accuracy: 0.7533 - val_loss: 0.6480 - val_accuracy: 0.7420\n",
            "Epoch 11/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6164 - accuracy: 0.7602 - val_loss: 0.6659 - val_accuracy: 0.7540\n",
            "Epoch 12/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6127 - accuracy: 0.7636 - val_loss: 0.6872 - val_accuracy: 0.7480\n",
            "Epoch 13/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6080 - accuracy: 0.7688 - val_loss: 0.6890 - val_accuracy: 0.7440\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 27ms/step - loss: 0.6919 - accuracy: 0.6667 - val_loss: 0.6803 - val_accuracy: 0.6950\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6618 - accuracy: 0.7031 - val_loss: 0.6787 - val_accuracy: 0.6920\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6485 - accuracy: 0.7193 - val_loss: 0.6836 - val_accuracy: 0.7300\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6433 - accuracy: 0.7255 - val_loss: 0.6720 - val_accuracy: 0.7010\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6380 - accuracy: 0.7337 - val_loss: 0.6652 - val_accuracy: 0.7240\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6285 - accuracy: 0.7413 - val_loss: 0.6810 - val_accuracy: 0.7290\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.6227 - accuracy: 0.7482 - val_loss: 0.7193 - val_accuracy: 0.7290\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6140 - accuracy: 0.7521 - val_loss: 0.6971 - val_accuracy: 0.7420\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 29ms/step - loss: 0.2127 - accuracy: 0.6820 - val_loss: 0.1915 - val_accuracy: 0.7140\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1841 - accuracy: 0.7354 - val_loss: 0.1857 - val_accuracy: 0.7340\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1724 - accuracy: 0.7534 - val_loss: 0.1809 - val_accuracy: 0.7430\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1667 - accuracy: 0.7650 - val_loss: 0.1817 - val_accuracy: 0.7400\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1651 - accuracy: 0.7673 - val_loss: 0.1759 - val_accuracy: 0.7600\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1562 - accuracy: 0.7800 - val_loss: 0.1765 - val_accuracy: 0.7470\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1506 - accuracy: 0.7901 - val_loss: 0.1786 - val_accuracy: 0.7520\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1430 - accuracy: 0.8042 - val_loss: 0.1839 - val_accuracy: 0.7580\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 27ms/step - loss: 0.2135 - accuracy: 0.6775 - val_loss: 0.1977 - val_accuracy: 0.7050\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1838 - accuracy: 0.7345 - val_loss: 0.1836 - val_accuracy: 0.7400\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1759 - accuracy: 0.7506 - val_loss: 0.1872 - val_accuracy: 0.7190\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1704 - accuracy: 0.7588 - val_loss: 0.1802 - val_accuracy: 0.7550\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1644 - accuracy: 0.7679 - val_loss: 0.1799 - val_accuracy: 0.7440\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1575 - accuracy: 0.7746 - val_loss: 0.1820 - val_accuracy: 0.7400\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1549 - accuracy: 0.7873 - val_loss: 0.1831 - val_accuracy: 0.7560\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1474 - accuracy: 0.7924 - val_loss: 0.1882 - val_accuracy: 0.7470\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 26ms/step - loss: 0.2153 - accuracy: 0.6873 - val_loss: 0.1919 - val_accuracy: 0.7200\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1839 - accuracy: 0.7355 - val_loss: 0.1823 - val_accuracy: 0.7360\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1735 - accuracy: 0.7512 - val_loss: 0.1808 - val_accuracy: 0.7380\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1705 - accuracy: 0.7553 - val_loss: 0.1773 - val_accuracy: 0.7510\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1651 - accuracy: 0.7663 - val_loss: 0.1776 - val_accuracy: 0.7550\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1599 - accuracy: 0.7734 - val_loss: 0.1772 - val_accuracy: 0.7510\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1526 - accuracy: 0.7848 - val_loss: 0.1856 - val_accuracy: 0.7330\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1493 - accuracy: 0.7896 - val_loss: 0.1855 - val_accuracy: 0.7400\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1426 - accuracy: 0.8021 - val_loss: 0.1899 - val_accuracy: 0.7230\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 27ms/step - loss: 0.7961 - accuracy: 0.5985 - val_loss: 0.7056 - val_accuracy: 0.6610\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6700 - accuracy: 0.6880 - val_loss: 0.6778 - val_accuracy: 0.7050\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.6674 - accuracy: 0.7091 - val_loss: 0.6956 - val_accuracy: 0.6800\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.6662 - accuracy: 0.6993 - val_loss: 0.7157 - val_accuracy: 0.6260\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.7027 - accuracy: 0.6315 - val_loss: 0.7525 - val_accuracy: 0.6270\n",
            "32/32 [==============================] - 1s 7ms/step\n",
            "27/27 [==============================] - 0s 6ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 6s 30ms/step - loss: 0.7128 - accuracy: 0.6592 - val_loss: 0.6978 - val_accuracy: 0.6900\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6697 - accuracy: 0.7033 - val_loss: 0.6803 - val_accuracy: 0.6900\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6524 - accuracy: 0.7185 - val_loss: 0.6813 - val_accuracy: 0.7000\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6451 - accuracy: 0.7356 - val_loss: 0.6716 - val_accuracy: 0.7290\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6335 - accuracy: 0.7408 - val_loss: 0.6546 - val_accuracy: 0.7360\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6938 - accuracy: 0.6599 - val_loss: 0.7397 - val_accuracy: 0.5520\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6805 - accuracy: 0.6767 - val_loss: 0.6884 - val_accuracy: 0.6800\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6492 - accuracy: 0.7205 - val_loss: 0.6726 - val_accuracy: 0.7110\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 27ms/step - loss: 0.7036 - accuracy: 0.6599 - val_loss: 0.6937 - val_accuracy: 0.6860\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6660 - accuracy: 0.7007 - val_loss: 0.6964 - val_accuracy: 0.6940\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.6535 - accuracy: 0.7201 - val_loss: 0.6661 - val_accuracy: 0.7200\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6409 - accuracy: 0.7391 - val_loss: 0.6604 - val_accuracy: 0.7330\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.6310 - accuracy: 0.7498 - val_loss: 0.7182 - val_accuracy: 0.7480\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.6808 - accuracy: 0.6854 - val_loss: 0.7437 - val_accuracy: 0.5970\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6825 - accuracy: 0.6722 - val_loss: 0.6834 - val_accuracy: 0.7040\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 10s 29ms/step - loss: 0.2053 - accuracy: 0.7040 - val_loss: 0.1918 - val_accuracy: 0.7320\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1770 - accuracy: 0.7510 - val_loss: 0.1752 - val_accuracy: 0.7410\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1679 - accuracy: 0.7600 - val_loss: 0.1755 - val_accuracy: 0.7530\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1593 - accuracy: 0.7751 - val_loss: 0.1749 - val_accuracy: 0.7560\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1508 - accuracy: 0.7889 - val_loss: 0.1801 - val_accuracy: 0.7520\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1389 - accuracy: 0.8079 - val_loss: 0.1817 - val_accuracy: 0.7540\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1259 - accuracy: 0.8288 - val_loss: 0.1971 - val_accuracy: 0.7290\n",
            "32/32 [==============================] - 1s 7ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 5s 28ms/step - loss: 0.2193 - accuracy: 0.6822 - val_loss: 0.1928 - val_accuracy: 0.7240\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1782 - accuracy: 0.7435 - val_loss: 0.1749 - val_accuracy: 0.7520\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1681 - accuracy: 0.7641 - val_loss: 0.1735 - val_accuracy: 0.7610\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1585 - accuracy: 0.7785 - val_loss: 0.1748 - val_accuracy: 0.7480\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1520 - accuracy: 0.7853 - val_loss: 0.1746 - val_accuracy: 0.7540\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1414 - accuracy: 0.8042 - val_loss: 0.1800 - val_accuracy: 0.7450\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 7ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 6s 27ms/step - loss: 0.2135 - accuracy: 0.6863 - val_loss: 0.1883 - val_accuracy: 0.7290\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1768 - accuracy: 0.7462 - val_loss: 0.1774 - val_accuracy: 0.7510\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1679 - accuracy: 0.7636 - val_loss: 0.1758 - val_accuracy: 0.7440\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1578 - accuracy: 0.7766 - val_loss: 0.1776 - val_accuracy: 0.7400\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1483 - accuracy: 0.7904 - val_loss: 0.1872 - val_accuracy: 0.7340\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1388 - accuracy: 0.8074 - val_loss: 0.1875 - val_accuracy: 0.7320\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 6s 29ms/step - loss: 1.0994 - accuracy: 0.4421 - val_loss: 0.8017 - val_accuracy: 0.5310\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.7119 - accuracy: 0.6042 - val_loss: 0.7179 - val_accuracy: 0.6350\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6784 - accuracy: 0.6848 - val_loss: 0.6926 - val_accuracy: 0.6680\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6720 - accuracy: 0.6923 - val_loss: 0.6911 - val_accuracy: 0.6790\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6660 - accuracy: 0.7024 - val_loss: 0.6947 - val_accuracy: 0.6800\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6454 - accuracy: 0.7340 - val_loss: 0.6706 - val_accuracy: 0.7250\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6362 - accuracy: 0.7490 - val_loss: 0.6716 - val_accuracy: 0.7460\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6199 - accuracy: 0.7609 - val_loss: 0.6803 - val_accuracy: 0.7490\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6190 - accuracy: 0.7590 - val_loss: 0.6649 - val_accuracy: 0.7330\n",
            "Epoch 10/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6183 - accuracy: 0.7620 - val_loss: 0.6892 - val_accuracy: 0.7430\n",
            "Epoch 11/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 1.0492 - accuracy: 0.5028 - val_loss: 0.9431 - val_accuracy: 0.5370\n",
            "Epoch 12/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.9546 - accuracy: 0.5767 - val_loss: 0.9623 - val_accuracy: 0.4770\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 6s 27ms/step - loss: 0.7571 - accuracy: 0.6415 - val_loss: 0.7158 - val_accuracy: 0.6490\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6711 - accuracy: 0.6984 - val_loss: 0.6994 - val_accuracy: 0.6680\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.6445 - accuracy: 0.7373 - val_loss: 0.6555 - val_accuracy: 0.7300\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.6288 - accuracy: 0.7516 - val_loss: 0.6734 - val_accuracy: 0.7450\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6238 - accuracy: 0.7530 - val_loss: 0.7005 - val_accuracy: 0.7450\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6121 - accuracy: 0.7653 - val_loss: 0.6538 - val_accuracy: 0.7460\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6036 - accuracy: 0.7708 - val_loss: 0.6876 - val_accuracy: 0.7480\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6183 - accuracy: 0.7618 - val_loss: 1.0134 - val_accuracy: 0.7510\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.7980 - accuracy: 0.5826 - val_loss: 0.6976 - val_accuracy: 0.6670\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "48/48 [==============================] - 6s 26ms/step - loss: 0.8107 - accuracy: 0.6127 - val_loss: 0.6927 - val_accuracy: 0.6720\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6607 - accuracy: 0.7100 - val_loss: 0.6701 - val_accuracy: 0.7080\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.8399 - accuracy: 0.5435 - val_loss: 0.7345 - val_accuracy: 0.5840\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6799 - accuracy: 0.6734 - val_loss: 0.6869 - val_accuracy: 0.6820\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6581 - accuracy: 0.7151 - val_loss: 0.6717 - val_accuracy: 0.7100\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "27/27 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_one_results = pd.read_csv(grid_search_one_path, index_col=0)"
      ],
      "metadata": {
        "id": "Mk-L2lcf_UBz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_one_results.groupby('learning_rate')['f1_score_validation'].mean(), grid_search_one_results.groupby('learning_rate')['f1_score_validation'].std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBS9JGcwlGrs",
        "outputId": "afdf1da1-55e9-4d66-d119-d9b2b7833afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(learning_rate\n",
              " 0.0005    0.683110\n",
              " 0.0010    0.684878\n",
              " 0.0030    0.663896\n",
              " Name: f1_score_validation, dtype: float64,\n",
              " learning_rate\n",
              " 0.0005    0.036464\n",
              " 0.0010    0.043555\n",
              " 0.0030    0.076131\n",
              " Name: f1_score_validation, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_idx = grid_search_one_results.groupby(['epochs', 'learning_rate', 'activation', 'loss_function', 'batch_size', 'optimizer']).mean()['f1_score_validation'].idxmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NElusAIk55He",
        "outputId": "338463e0-6245-4018-fb33-00ba31490010"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-3e95c5e15e32>:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  max_idx = grid_search_one_results.groupby(['epochs', 'learning_rate', 'activation', 'loss_function', 'batch_size', 'optimizer']).mean()['f1_score_validation'].idxmax()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_one_results.groupby(['epochs', 'learning_rate', 'activation', 'loss_function', 'batch_size', 'optimizer']).std().loc[max_idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFkHymeU7vhy",
        "outputId": "b363a2df-4d83-4df6-b752-70fa07ec90b1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-a462ac4317dc>:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.std is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  grid_search_one_results.groupby(['epochs', 'learning_rate', 'activation', 'loss_function', 'batch_size', 'optimizer']).std().loc[max_idx]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "f1_score_validation    0.005852\n",
              "f1_score_test          0.013419\n",
              "run_number             1.000000\n",
              "Name: (50, 0.001, relu, poisson, 64, <class 'keras.src.optimizers.adam.Adam'>), dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8JFUFC4-GMP",
        "outputId": "b1df9e33-aae3-4ada-cb55-fd6a819ed74a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 0.001, 'relu', 'poisson', 64, \"<class 'keras.src.optimizers.adam.Adam'>\")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation: Offensiveness metric"
      ],
      "metadata": {
        "id": "G4GkEgp8hry7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set-up model with best parameters from grid search"
      ],
      "metadata": {
        "id": "7lX_7jegh2lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_lstm_model = create_model_adaptive(\n",
        "  y_train=y_train,\n",
        "  emb_matrix=emb_matrix,\n",
        "  learning_rate=0.001,\n",
        "  loss_function='poisson',\n",
        "  activation='relu',\n",
        "  optimizer=Adam,\n",
        "  layers=set_up_candidate_one([]),\n",
        ")\n",
        "\n",
        "best_lstm_model = train_model_adaptive(\n",
        "  model=best_lstm_model,\n",
        "  X_train=X_train_vect,\n",
        "  y_train=y_train_bin,\n",
        "  X_val=X_val_vect,\n",
        "  y_val=y_val_bin,\n",
        "  epochs=5,\n",
        "  batch_size=64,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baff329f-eca7-4763-8024-508789a7f4fd",
        "id": "ezCeJAfp-Sbc"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "192/192 [==============================] - 8s 18ms/step - loss: 0.6870 - accuracy: 0.6806 - val_loss: 0.6745 - val_accuracy: 0.7010\n",
            "Epoch 2/5\n",
            "192/192 [==============================] - 3s 12ms/step - loss: 0.6655 - accuracy: 0.7007 - val_loss: 0.6936 - val_accuracy: 0.6500\n",
            "Epoch 3/5\n",
            "192/192 [==============================] - 3s 12ms/step - loss: 0.6480 - accuracy: 0.7306 - val_loss: 0.6585 - val_accuracy: 0.7310\n",
            "Epoch 4/5\n",
            "192/192 [==============================] - 3s 12ms/step - loss: 0.6590 - accuracy: 0.7113 - val_loss: 0.6674 - val_accuracy: 0.7260\n",
            "Epoch 5/5\n",
            "192/192 [==============================] - 4s 17ms/step - loss: 0.6957 - accuracy: 0.6738 - val_loss: 0.6822 - val_accuracy: 0.7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test_best_raw = best_lstm_model.predict(X_test_vect)\n",
        "y_pred_test_best = [[1] if n > 0.5 else [0] for [n] in best_lstm_model.predict(X_test_vect)]\n",
        "y_pred_test_best_f1 = f1_score(y_test_bin, y_pred_test_best, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65m9jTMt_V7m",
        "outputId": "8c6edfd9-88df-45a1-9725-db93a243138f"
      },
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 4ms/step\n",
            "27/27 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test_best_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF99a4sDACRH",
        "outputId": "1301842b-08bc-473c-a961-14e0aa2432cb"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6392377724614566"
            ]
          },
          "metadata": {},
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define offensiveness metric functions"
      ],
      "metadata": {
        "id": "GUu0kArch8um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_word_frequency(X_test_vect, vocabulary):\n",
        "  word_counts = {word: 0 for word in vocabulary}\n",
        "  for sentence in X_train_vect:\n",
        "    for word_index in sentence:\n",
        "      if word_index != 0: # If the word exists in the vocabulary increment the occurence count\n",
        "        word_counts[vocabulary[word_index]] += 1\n",
        "  return word_counts"
      ],
      "metadata": {
        "id": "ykJ5i6OsA-o0"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_word_frequency_in_offensive_instances(X_test_vect, y_pred_test, vocabulary):\n",
        "  total_offensive_classifications = sum([1 if predicted_label == [1] else 0 for predicted_label in y_pred_test])\n",
        "  word_counts = {word: 0 for word in vocabulary}\n",
        "  for (sentence, predicted_label) in zip(X_train_vect, y_pred_test):\n",
        "    if predicted_label == [1]: # If the data instance is predicted as offensive add it's o\n",
        "      for word_index in sentence:\n",
        "        if word_index != 0:\n",
        "          word_counts[vocabulary[word_index]] += (1)\n",
        "  return {k: v for k, v in sorted(word_counts.items(), key=lambda item: item[1], reverse=True)}"
      ],
      "metadata": {
        "id": "hY3S6tlUGAa6"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_normalized_word_frequency_in_offensive_instances(word_frequency, word_frequency_in_offensive_instances, voc, support_threshold):\n",
        "  normalized_word_frequency_in_offensive_instances = {}\n",
        "  for word in voc:\n",
        "    if word_frequency[word] != 0 and word_frequency[word] >= support_threshold:\n",
        "      normalized_word_frequency_in_offensive_instances[word] = word_frequency_in_offensive_instances[word] / word_frequency[word]\n",
        "  return {k: v for k, v in sorted(normalized_word_frequency_in_offensive_instances.items(), key=lambda item: item[1], reverse=True)}"
      ],
      "metadata": {
        "id": "p_i3e3FwHsdQ"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_offensiveness_metric(X, y_pred, voc):\n",
        "  word_frequency = compute_word_frequency(X, voc)\n",
        "  word_frequency_in_offensive_instances = compute_word_frequency_in_offensive_instances(X, y_pred, voc)\n",
        "  normalized_word_frequency_in_offensive_instances = compute_normalized_word_frequency_in_offensive_instances(word_frequency, word_frequency_in_offensive_instances, voc, 10)\n",
        "  return normalized_word_frequency_in_offensive_instances"
      ],
      "metadata": {
        "id": "nFxpIuNCFHum"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_based_on_word_list(X, word_list):\n",
        "  y_pred = []\n",
        "  for sentence in X:\n",
        "    prediction = [0]\n",
        "    for word_token in sentence:\n",
        "      if word_token in word_list:\n",
        "        prediction = [1]\n",
        "    y_pred.append(prediction)\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "_l240E44b33K"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = [[1] if n > 0.5 else [0] for [n] in best_lstm_model.predict(X_train_vect)]\n",
        "normalized_word_frequency_in_offensive_instances_train = compute_offensiveness_metric(X_train_vect, y_pred_train, voc)\n",
        "word_list_train = list(normalized_word_frequency_in_offensive_instances_train.keys())[:100]\n",
        "# This is a bit hacky, but use the tokenizer to convert the words back to their original token indexes\n",
        "word_list_tokens_train = [int(word[0]) for word in vectorizer(word_list_train)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkpTrajZealk",
        "outputId": "9ef73fbe-97a6-4dbe-ba3b-4ba07e5f7787"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_word_list = classify_based_on_word_list(X_test_vect, word_list_tokens_train)\n",
        "f1_score(y_test_bin, y_pred_word_list, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftlCpXKvdsbs",
        "outputId": "7e73054d-df2f-49e6-bf44-38586272508f"
      },
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6486928104575163"
            ]
          },
          "metadata": {},
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAsd80kXjc0m",
        "outputId": "790bb561-fc50-4263-97ff-406570e068a5"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nigga',\n",
              " 'nut',\n",
              " 'bitch',\n",
              " 'bitches',\n",
              " 'disgusting',\n",
              " 'fucked',\n",
              " 'niggas',\n",
              " 'fuck',\n",
              " 'dumb',\n",
              " 'dick',\n",
              " 'crap',\n",
              " 'nuts',\n",
              " 'scum',\n",
              " 'racists',\n",
              " 'fucking',\n",
              " 'idiot',\n",
              " 'ass',\n",
              " 'spoiled',\n",
              " 'moron',\n",
              " 'loser',\n",
              " 'liar',\n",
              " 'vile',\n",
              " 'shit',\n",
              " 'pussy',\n",
              " 'stupid',\n",
              " 'racist',\n",
              " 'outrage',\n",
              " 'dude',\n",
              " 'hateful',\n",
              " 'dirty',\n",
              " 'weak',\n",
              " 'gotta',\n",
              " 'fascist',\n",
              " 'ignorant',\n",
              " 'destroying',\n",
              " 'sick',\n",
              " 'bigger',\n",
              " 'mouth',\n",
              " 'damn',\n",
              " 'lying',\n",
              " 'Holy',\n",
              " 'ugly',\n",
              " 'clown',\n",
              " 'idiots',\n",
              " 'delusional',\n",
              " 'sucks',\n",
              " 'hell',\n",
              " 'fool',\n",
              " 'bunch',\n",
              " 'drunk',\n",
              " 'honestly',\n",
              " 'nobody',\n",
              " 'quit',\n",
              " 'thugs',\n",
              " 'strangers',\n",
              " 'nazi',\n",
              " 'complaining',\n",
              " 'ruined',\n",
              " 'horrible',\n",
              " 'tired',\n",
              " 'ruin',\n",
              " 'shit.',\n",
              " 'bullshit',\n",
              " 'trash',\n",
              " 'republicans',\n",
              " 'doesnt',\n",
              " 'cops',\n",
              " 'accusation',\n",
              " 'scare',\n",
              " 'gang',\n",
              " 'fat',\n",
              " 'lmao',\n",
              " 'beating',\n",
              " 'fake',\n",
              " 'rape',\n",
              " 'murder',\n",
              " 'attacks',\n",
              " 'mad',\n",
              " 'dying',\n",
              " 'piss',\n",
              " 'letting',\n",
              " 'hilarious',\n",
              " 'filled',\n",
              " 'apart',\n",
              " 'hate',\n",
              " 'hurt',\n",
              " 'disgrace',\n",
              " 'shame',\n",
              " 'libs',\n",
              " 'destroy',\n",
              " 'babies',\n",
              " 'somebody',\n",
              " 'Tom',\n",
              " 'create',\n",
              " 'oh',\n",
              " 'broke',\n",
              " 'professor',\n",
              " 'hates',\n",
              " 'burn',\n",
              " 'kill']"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    }
  ]
}